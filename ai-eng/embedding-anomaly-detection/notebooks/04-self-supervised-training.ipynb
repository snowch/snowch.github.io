{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Appendix: Self-Supervised Training\n\nTrain TabularResNet on OCSF data using self-supervised contrastive learning.\n\n**What you'll learn:**\n1. Contrastive learning for tabular data\n2. Data augmentation strategies for OCSF events\n3. Training loop implementation\n4. Extracting embeddings for downstream tasks\n\n**Prerequisites:**\n- Processed features from [03-feature-engineering.ipynb](03-feature-engineering.ipynb)\n- PyTorch installed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Load Processed Features\n\nLoad the numerical and categorical feature arrays from the feature engineering notebook."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature arrays\n",
    "numerical = np.load('../data/numerical_features.npy')\n",
    "categorical = np.load('../data/categorical_features.npy')\n",
    "\n",
    "# Load artifacts (encoders, scaler, cardinalities)\n",
    "with open('../data/feature_artifacts.pkl', 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "cardinalities = artifacts['cardinalities']\n",
    "\n",
    "print(f\"Numerical features: {numerical.shape}\")\n",
    "print(f\"Categorical features: {categorical.shape}\")\n",
    "print(f\"Cardinalities: {cardinalities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "numerical_tensor = torch.tensor(numerical, dtype=torch.float32)\n",
    "categorical_tensor = torch.tensor(categorical, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = TensorDataset(numerical_tensor, categorical_tensor)\n",
    "batch_size = 256  # Large batches are important for contrastive learning\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Batches per epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define TabularResNet Model\n",
    "\n",
    "A simplified TabularResNet that creates embeddings from mixed numerical/categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with two linear layers and skip connection.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_model)\n",
    "        self.linear2 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First sub-layer\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = F.gelu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Second sub-layer\n",
    "        x = self.norm2(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class TabularResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-style architecture for tabular data.\n",
    "    \n",
    "    Combines:\n",
    "    - Categorical embeddings\n",
    "    - Numerical feature projection\n",
    "    - Residual blocks for deep feature learning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_numerical, cardinalities, d_model=128, \n",
    "                 num_blocks=4, embedding_dim=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Categorical embeddings\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cardinality, embedding_dim)\n",
    "            for cardinality in cardinalities\n",
    "        ])\n",
    "        \n",
    "        # Calculate input dimension\n",
    "        total_cat_dim = len(cardinalities) * embedding_dim\n",
    "        input_dim = num_numerical + total_cat_dim\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(d_model, dropout) \n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Final layer norm\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, numerical, categorical, return_embedding=True):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            numerical: (batch, num_numerical) tensor\n",
    "            categorical: (batch, num_categorical) tensor of indices\n",
    "            return_embedding: If True, return embeddings instead of logits\n",
    "        \"\"\"\n",
    "        # Embed categorical features\n",
    "        cat_embedded = []\n",
    "        for i, emb_layer in enumerate(self.embeddings):\n",
    "            cat_embedded.append(emb_layer(categorical[:, i]))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        if cat_embedded:\n",
    "            cat_concat = torch.cat(cat_embedded, dim=1)\n",
    "            x = torch.cat([numerical, cat_concat], dim=1)\n",
    "        else:\n",
    "            x = numerical\n",
    "        \n",
    "        # Project to model dimension\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Apply residual blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Final normalization\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = TabularResNet(\n",
    "    num_numerical=numerical.shape[1],\n",
    "    cardinalities=cardinalities,\n",
    "    d_model=128,\n",
    "    num_blocks=4,\n",
    "    embedding_dim=32,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Contrastive Learning Components\n",
    "\n",
    "**Contrastive learning** trains the model so that:\n",
    "- Similar records (augmented versions of the same event) have similar embeddings\n",
    "- Different records have different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularAugmentation:\n",
    "    \"\"\"\n",
    "    Data augmentation for tabular data.\n",
    "    \n",
    "    For OCSF data, we only augment:\n",
    "    - Numerical: Add small Gaussian noise (5-10%)\n",
    "    - Categorical: Random dropout (10-20%) - replaces with random value\n",
    "    \n",
    "    We DON'T augment security-critical fields like status, severity, activity_id.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, noise_level=0.1, dropout_prob=0.15):\n",
    "        self.noise_level = noise_level\n",
    "        self.dropout_prob = dropout_prob\n",
    "    \n",
    "    def augment_numerical(self, numerical):\n",
    "        \"\"\"Add Gaussian noise to numerical features.\"\"\"\n",
    "        noise = torch.randn_like(numerical) * self.noise_level\n",
    "        return numerical + noise\n",
    "    \n",
    "    def augment_categorical(self, categorical, cardinalities):\n",
    "        \"\"\"Randomly replace some categorical features.\"\"\"\n",
    "        augmented = categorical.clone()\n",
    "        mask = torch.rand_like(categorical.float()) < self.dropout_prob\n",
    "        \n",
    "        for i, cardinality in enumerate(cardinalities):\n",
    "            random_cats = torch.randint(\n",
    "                0, cardinality, (categorical.size(0),),\n",
    "                device=categorical.device\n",
    "            )\n",
    "            augmented[:, i] = torch.where(\n",
    "                mask[:, i], random_cats, categorical[:, i]\n",
    "            )\n",
    "        \n",
    "        return augmented\n",
    "\n",
    "\n",
    "def contrastive_loss(model, numerical, categorical, cardinalities, \n",
    "                     temperature=0.07, augmenter=None):\n",
    "    \"\"\"\n",
    "    SimCLR-style contrastive loss for tabular data.\n",
    "    \n",
    "    For each record:\n",
    "    1. Create two augmented views\n",
    "    2. Compute embeddings for both views\n",
    "    3. Pull embeddings of same record together (positive pairs)\n",
    "    4. Push embeddings of different records apart (negative pairs)\n",
    "    \"\"\"\n",
    "    if augmenter is None:\n",
    "        augmenter = TabularAugmentation()\n",
    "    \n",
    "    batch_size = numerical.size(0)\n",
    "    \n",
    "    # Create two augmented views\n",
    "    num_aug1 = augmenter.augment_numerical(numerical)\n",
    "    cat_aug1 = augmenter.augment_categorical(categorical, cardinalities)\n",
    "    emb1 = model(num_aug1, cat_aug1)\n",
    "    \n",
    "    num_aug2 = augmenter.augment_numerical(numerical)\n",
    "    cat_aug2 = augmenter.augment_categorical(categorical, cardinalities)\n",
    "    emb2 = model(num_aug2, cat_aug2)\n",
    "    \n",
    "    # Concatenate embeddings: [view1_batch, view2_batch]\n",
    "    embeddings = torch.cat([emb1, emb2], dim=0)\n",
    "    \n",
    "    # Normalize (important for cosine similarity)\n",
    "    embeddings = F.normalize(embeddings, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity = torch.matmul(embeddings, embeddings.T) / temperature\n",
    "    \n",
    "    # Labels: positive pairs are (i, i+batch_size)\n",
    "    labels = torch.cat([\n",
    "        torch.arange(batch_size, 2 * batch_size),\n",
    "        torch.arange(0, batch_size)\n",
    "    ], dim=0).to(numerical.device)\n",
    "    \n",
    "    # Mask self-similarity\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=numerical.device)\n",
    "    similarity = similarity.masked_fill(mask, float('-inf'))\n",
    "    \n",
    "    # Cross-entropy loss\n",
    "    loss = F.cross_entropy(similarity, labels)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Test the loss function\n",
    "augmenter = TabularAugmentation(noise_level=0.1, dropout_prob=0.15)\n",
    "\n",
    "# Get a batch\n",
    "num_batch, cat_batch = next(iter(dataloader))\n",
    "num_batch = num_batch.to(device)\n",
    "cat_batch = cat_batch.to(device)\n",
    "\n",
    "# Compute loss\n",
    "loss = contrastive_loss(model, num_batch, cat_batch, cardinalities, augmenter=augmenter)\n",
    "print(f\"Initial contrastive loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop\n",
    "\n",
    "Train the model using contrastive learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, cardinalities, augmenter, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for numerical, categorical in dataloader:\n",
    "        numerical = numerical.to(device)\n",
    "        categorical = categorical.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = contrastive_loss(\n",
    "            model, numerical, categorical, cardinalities,\n",
    "            augmenter=augmenter\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Training configuration\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "augmenter = TabularAugmentation(noise_level=0.1, dropout_prob=0.15)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Epochs: {num_epochs}, Batch size: {batch_size}, LR: {learning_rate}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(model, dataloader, optimizer, cardinalities, augmenter, device)\n",
    "    scheduler.step()\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        print(f\"Epoch {epoch+1:3d}/{num_epochs} | Loss: {loss:.4f} | LR: {lr:.6f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses, marker='o', markersize=4)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Contrastive Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Embeddings\n",
    "\n",
    "Use the trained model to create embeddings for all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_embeddings(model, numerical, categorical, batch_size=512):\n",
    "    \"\"\"\n",
    "    Extract embeddings for all records.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings (N, d_model)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(numerical, dtype=torch.float32),\n",
    "        torch.tensor(categorical, dtype=torch.long)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for num_batch, cat_batch in loader:\n",
    "        num_batch = num_batch.to(device)\n",
    "        cat_batch = cat_batch.to(device)\n",
    "        \n",
    "        emb = model(num_batch, cat_batch)\n",
    "        embeddings.append(emb.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Extract embeddings\n",
    "embeddings = extract_embeddings(model, numerical, categorical)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings and model\n",
    "np.save('../data/embeddings.npy', embeddings)\n",
    "torch.save(model.state_dict(), '../data/tabular_resnet.pt')\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  - ../data/embeddings.npy\")\n",
    "print(\"  - ../data/tabular_resnet.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Embedding Visualization\n",
    "\n",
    "Use t-SNE to visualize the learned embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample for visualization (t-SNE is slow on large datasets)\n",
    "sample_size = min(2000, len(embeddings))\n",
    "indices = np.random.choice(len(embeddings), sample_size, replace=False)\n",
    "emb_sample = embeddings[indices]\n",
    "\n",
    "# Run t-SNE\n",
    "print(\"Running t-SNE (this may take a minute)...\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "emb_2d = tsne.fit_transform(emb_sample)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(emb_2d[:, 0], emb_2d[:, 1], alpha=0.5, s=10)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.title('OCSF Event Embeddings (t-SNE)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nIn this notebook, we:\n\n1. **Loaded processed features** from the feature engineering notebook\n2. **Built TabularResNet** - categorical embeddings + residual blocks\n3. **Implemented contrastive learning** - SimCLR-style with augmentation\n4. **Trained the model** on unlabeled OCSF data\n5. **Extracted embeddings** for all records\n\n**Key insight**: We learned meaningful representations from unlabeled data by training the model to recognize that augmented versions of the same event should have similar embeddings.\n\n**Next**: Use these embeddings in:\n- [05-embedding-analysis.ipynb](05-embedding-analysis.ipynb) - Analyze embedding quality\n- [06-anomaly-detection.ipynb](06-anomaly-detection.ipynb) - Detect anomalies using embeddings"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}