{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Appendix: Self-Supervised Training\n\n> **Theory**: See [Part 4: Self-Supervised Training](../part4-self-supervised-training.md) for the concepts behind contrastive learning.\n\nTrain TabularResNet on OCSF data using self-supervised contrastive learning.\n\n**What you'll learn:**\n1. Contrastive learning for tabular data\n2. Data augmentation strategies for OCSF events\n3. Training loop implementation\n4. Extracting embeddings for downstream tasks\n\n**Prerequisites:**\n- Processed features from [03-feature-engineering.ipynb](03-feature-engineering.ipynb)\n- PyTorch installed\n\n---\n\n## Key Concept: Self-Supervised Learning\n\n**Problem**: We have millions of OCSF logs but **no labels** (normal vs anomaly).\n\n**Solution**: Self-supervised learning creates a training signal from the data itself:\n1. Take a log event and create two **augmented versions** (add noise, mask features)\n2. Train the model to recognize that both versions came from the **same event**\n3. The model learns meaningful representations without needing labels"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"  (Training will be slower on CPU, but still works fine for this dataset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Load Processed Features\n\nLoad the numerical and categorical feature arrays from the feature engineering notebook.\n\n**What you should expect:**\n- Numerical features: `(N, 9)` - normalized floats\n- Categorical features: `(N, 12)` - integer indices\n- Cardinalities: list of vocab sizes for each categorical column\n\n**If you see errors:**\n- `FileNotFoundError`: Run notebook 03 first to generate the feature files\n- Shape mismatch: Ensure you're using the same data version"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature arrays\n",
    "numerical = np.load('../data/numerical_features.npy')\n",
    "categorical = np.load('../data/categorical_features.npy')\n",
    "\n",
    "# Load artifacts (encoders, scaler, cardinalities)\n",
    "with open('../data/feature_artifacts.pkl', 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "cardinalities = artifacts['cardinalities']\n",
    "\n",
    "print(\"Loaded Features:\")\n",
    "print(f\"  Numerical: {numerical.shape} (float32)\")\n",
    "print(f\"  Categorical: {categorical.shape} (int64)\")\n",
    "print(f\"  Cardinalities: {cardinalities}\")\n",
    "print(f\"  Total embedding params: {sum(c * 32 for c in cardinalities):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "numerical_tensor = torch.tensor(numerical, dtype=torch.float32)\n",
    "categorical_tensor = torch.tensor(categorical, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "# Large batches are IMPORTANT for contrastive learning (more negatives)\n",
    "dataset = TensorDataset(numerical_tensor, categorical_tensor)\n",
    "batch_size = 256\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f\"\\nDataLoader:\")\n",
    "print(f\"  Dataset size: {len(dataset):,} events\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Batches per epoch: {len(dataloader)}\")\n",
    "print(f\"  (drop_last=True: last incomplete batch dropped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define TabularResNet Model\n",
    "\n",
    "A ResNet-style architecture adapted for tabular data:\n",
    "- **Categorical embeddings**: Convert integer indices to dense vectors\n",
    "- **Input projection**: Combine numerical + embedded categorical features\n",
    "- **Residual blocks**: Deep feature learning with skip connections\n",
    "- **Output**: 128-dimensional embedding vector\n",
    "\n",
    "**What you should expect:**\n",
    "- ~100K-500K parameters (depends on cardinalities)\n",
    "- Model fits easily in memory (even on CPU)\n",
    "\n",
    "**If model is too large:**\n",
    "- Reduce `embedding_dim` (32 -> 16)\n",
    "- Reduce `d_model` (128 -> 64)\n",
    "- Reduce `num_blocks` (4 -> 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with two linear layers and skip connection.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_model)\n",
    "        self.linear2 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pre-norm residual connection\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = F.gelu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x + residual  # Skip connection\n",
    "\n",
    "\n",
    "class TabularResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-style architecture for tabular data.\n",
    "    \n",
    "    Architecture:\n",
    "        Input -> [Cat Embeddings + Numerical] -> Projection -> ResBlocks -> Output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_numerical, cardinalities, d_model=128, \n",
    "                 num_blocks=4, embedding_dim=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Categorical embeddings: one embedding layer per categorical feature\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cardinality, embedding_dim)\n",
    "            for cardinality in cardinalities\n",
    "        ])\n",
    "        \n",
    "        # Calculate input dimension\n",
    "        total_cat_dim = len(cardinalities) * embedding_dim\n",
    "        input_dim = num_numerical + total_cat_dim\n",
    "        \n",
    "        # Input projection to model dimension\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Stack of residual blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(d_model, dropout) \n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Final layer norm\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, numerical, categorical, return_embedding=True):\n",
    "        # Embed each categorical feature\n",
    "        cat_embedded = []\n",
    "        for i, emb_layer in enumerate(self.embeddings):\n",
    "            cat_embedded.append(emb_layer(categorical[:, i]))\n",
    "        \n",
    "        # Concatenate: [numerical, cat_emb_1, cat_emb_2, ...]\n",
    "        if cat_embedded:\n",
    "            cat_concat = torch.cat(cat_embedded, dim=1)\n",
    "            x = torch.cat([numerical, cat_concat], dim=1)\n",
    "        else:\n",
    "            x = numerical\n",
    "        \n",
    "        # Project to model dimension\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Apply residual blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Final normalization\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = TabularResNet(\n",
    "    num_numerical=numerical.shape[1],\n",
    "    cardinalities=cardinalities,\n",
    "    d_model=128,\n",
    "    num_blocks=4,\n",
    "    embedding_dim=32,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "print(f\"  Input: {numerical.shape[1]} numerical + {len(cardinalities)} categorical features\")\n",
    "print(f\"  Embedding dim: 32 per categorical\")\n",
    "print(f\"  Model dim (d_model): 128\")\n",
    "print(f\"  Residual blocks: 4\")\n",
    "print(f\"  Output: 128-dimensional embedding\")\n",
    "print(f\"\\nParameters: {total_params:,} ({trainable_params:,} trainable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Contrastive Learning Components\n",
    "\n",
    "**Contrastive learning** (SimCLR-style) trains the model so that:\n",
    "- **Positive pairs** (augmented versions of same event) \u2192 similar embeddings\n",
    "- **Negative pairs** (different events) \u2192 dissimilar embeddings\n",
    "\n",
    "### Data Augmentation for OCSF\n",
    "\n",
    "We augment tabular data by:\n",
    "1. **Numerical**: Add small Gaussian noise (5-10%)\n",
    "2. **Categorical**: Random dropout (10-20%) - replace with random value\n",
    "\n",
    "**What we DON'T augment**: Security-critical fields like `status`, `severity_id`, `activity_id` ideally shouldn't be heavily augmented (we use light augmentation here for simplicity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularAugmentation:\n",
    "    \"\"\"\n",
    "    Data augmentation for tabular data.\n",
    "    \n",
    "    For OCSF data:\n",
    "    - Numerical: Add small Gaussian noise\n",
    "    - Categorical: Random dropout (replace with random value)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, noise_level=0.1, dropout_prob=0.15):\n",
    "        self.noise_level = noise_level\n",
    "        self.dropout_prob = dropout_prob\n",
    "    \n",
    "    def augment_numerical(self, numerical):\n",
    "        \"\"\"Add Gaussian noise to numerical features.\"\"\"\n",
    "        noise = torch.randn_like(numerical) * self.noise_level\n",
    "        return numerical + noise\n",
    "    \n",
    "    def augment_categorical(self, categorical, cardinalities):\n",
    "        \"\"\"Randomly replace some categorical features with random values.\"\"\"\n",
    "        augmented = categorical.clone()\n",
    "        mask = torch.rand_like(categorical.float()) < self.dropout_prob\n",
    "        \n",
    "        for i, cardinality in enumerate(cardinalities):\n",
    "            random_cats = torch.randint(\n",
    "                0, cardinality, (categorical.size(0),),\n",
    "                device=categorical.device\n",
    "            )\n",
    "            augmented[:, i] = torch.where(\n",
    "                mask[:, i], random_cats, categorical[:, i]\n",
    "            )\n",
    "        \n",
    "        return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentation\n",
    "augmenter = TabularAugmentation(noise_level=0.1, dropout_prob=0.15)\n",
    "\n",
    "# Get a sample batch\n",
    "sample_num, sample_cat = next(iter(dataloader))\n",
    "\n",
    "# Augment\n",
    "aug_num = augmenter.augment_numerical(sample_num)\n",
    "aug_cat = augmenter.augment_categorical(sample_cat, cardinalities)\n",
    "\n",
    "# Show difference\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Numerical: show noise distribution\n",
    "noise = (aug_num - sample_num).numpy().flatten()\n",
    "axes[0].hist(noise, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Noise Added')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title(f'Numerical Augmentation (noise_level={augmenter.noise_level})')\n",
    "axes[0].annotate(f'std={noise.std():.3f}', xy=(0.7, 0.9), xycoords='axes fraction')\n",
    "\n",
    "# Categorical: show dropout rate\n",
    "changed = (aug_cat != sample_cat).float().mean(dim=0).numpy()\n",
    "axes[1].bar(range(len(changed)), changed, edgecolor='black')\n",
    "axes[1].axhline(augmenter.dropout_prob, color='red', linestyle='--', \n",
    "               label=f'target={augmenter.dropout_prob}')\n",
    "axes[1].set_xlabel('Categorical Feature Index')\n",
    "axes[1].set_ylabel('Fraction Changed')\n",
    "axes[1].set_title(f'Categorical Augmentation (dropout={augmenter.dropout_prob})')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Numerical: mean noise = {noise.mean():.4f}, std = {noise.std():.4f}\")\n",
    "print(f\"Categorical: average {changed.mean()*100:.1f}% of values changed per feature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### How to read these augmentation charts\n\n**Left (Numerical noise)**: Histogram of noise values added to numerical features.\n- Centered at 0 (no bias)\n- Width controlled by `noise_level` parameter\n- Too wide \u2192 augmented views too different \u2192 model can't learn\n- Too narrow \u2192 views too similar \u2192 model doesn't generalize\n\n**Right (Categorical dropout)**: Bar chart showing fraction of values changed per feature.\n- Red line = target dropout probability (15%)\n- Bars should hover around the red line\n- Higher bars = more aggressive augmentation for that feature",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(model, numerical, categorical, cardinalities, \n",
    "                     temperature=0.07, augmenter=None):\n",
    "    \"\"\"\n",
    "    SimCLR-style contrastive loss for tabular data.\n",
    "    \n",
    "    For each record in the batch:\n",
    "    1. Create two augmented views\n",
    "    2. Compute embeddings for both views\n",
    "    3. Pull embeddings of same record together (positive pairs)\n",
    "    4. Push embeddings of different records apart (negative pairs)\n",
    "    \n",
    "    Args:\n",
    "        temperature: Controls sharpness of similarity distribution\n",
    "                    Lower = sharper peaks (0.07 is typical)\n",
    "    \"\"\"\n",
    "    if augmenter is None:\n",
    "        augmenter = TabularAugmentation()\n",
    "    \n",
    "    batch_size = numerical.size(0)\n",
    "    \n",
    "    # Create two augmented views of each record\n",
    "    num_aug1 = augmenter.augment_numerical(numerical)\n",
    "    cat_aug1 = augmenter.augment_categorical(categorical, cardinalities)\n",
    "    emb1 = model(num_aug1, cat_aug1)\n",
    "    \n",
    "    num_aug2 = augmenter.augment_numerical(numerical)\n",
    "    cat_aug2 = augmenter.augment_categorical(categorical, cardinalities)\n",
    "    emb2 = model(num_aug2, cat_aug2)\n",
    "    \n",
    "    # Concatenate embeddings: [view1_batch, view2_batch]\n",
    "    embeddings = torch.cat([emb1, emb2], dim=0)  # (2*batch_size, d_model)\n",
    "    \n",
    "    # L2 normalize (important for cosine similarity)\n",
    "    embeddings = F.normalize(embeddings, dim=1)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    similarity = torch.matmul(embeddings, embeddings.T) / temperature\n",
    "    \n",
    "    # Labels: positive pairs are (i, i+batch_size) and (i+batch_size, i)\n",
    "    labels = torch.cat([\n",
    "        torch.arange(batch_size, 2 * batch_size),\n",
    "        torch.arange(0, batch_size)\n",
    "    ], dim=0).to(numerical.device)\n",
    "    \n",
    "    # Mask self-similarity (diagonal)\n",
    "    mask = torch.eye(2 * batch_size, dtype=torch.bool, device=numerical.device)\n",
    "    similarity = similarity.masked_fill(mask, float('-inf'))\n",
    "    \n",
    "    # Cross-entropy loss (treat as classification: which is the positive?)\n",
    "    loss = F.cross_entropy(similarity, labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the loss function\n",
    "augmenter = TabularAugmentation(noise_level=0.1, dropout_prob=0.15)\n",
    "\n",
    "# Get a batch\n",
    "num_batch, cat_batch = next(iter(dataloader))\n",
    "num_batch = num_batch.to(device)\n",
    "cat_batch = cat_batch.to(device)\n",
    "\n",
    "# Compute loss\n",
    "with torch.no_grad():\n",
    "    initial_loss = contrastive_loss(model, num_batch, cat_batch, cardinalities, augmenter=augmenter)\n",
    "\n",
    "print(f\"Initial contrastive loss: {initial_loss.item():.4f}\")\n",
    "print(f\"\\nExpected initial loss: ~{np.log(2 * batch_size - 1):.2f}\")\n",
    "print(f\"  (Random embeddings should give loss \u2248 log(num_negatives))\")\n",
    "print(f\"\\nGood training should reduce this significantly (target: < 3.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop\n",
    "\n",
    "Train the model using contrastive learning.\n",
    "\n",
    "**What you should expect:**\n",
    "- Initial loss: ~5.5 (for batch_size=256, this is log(511) \u2248 6.2)\n",
    "- Loss should decrease steadily each epoch\n",
    "- Final loss: typically 2.0-4.0 (lower = better alignment)\n",
    "- Training time: ~2-5 minutes on CPU, ~30 seconds on GPU\n",
    "\n",
    "**If loss doesn't decrease:**\n",
    "- Learning rate too high: try 1e-4 instead of 1e-3\n",
    "- Data issue: verify features are normalized properly\n",
    "- Augmentation too strong: reduce noise_level and dropout_prob\n",
    "\n",
    "**If loss goes to NaN:**\n",
    "- Learning rate too high\n",
    "- Numerical instability: check for NaN in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, cardinalities, augmenter, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for numerical, categorical in dataloader:\n",
    "        numerical = numerical.to(device)\n",
    "        categorical = categorical.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = contrastive_loss(\n",
    "            model, numerical, categorical, cardinalities,\n",
    "            augmenter=augmenter\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "augmenter = TabularAugmentation(noise_level=0.1, dropout_prob=0.15)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Learning rate: {learning_rate} (with cosine annealing)\")\n",
    "print(f\"  Optimizer: AdamW (weight_decay=0.01)\")\n",
    "print(f\"  Augmentation: noise={augmenter.noise_level}, dropout={augmenter.dropout_prob}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"{'Epoch':>6} | {'Loss':>8} | {'LR':>10} | {'Status'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train_epoch(model, dataloader, optimizer, cardinalities, augmenter, device)\n",
    "    scheduler.step()\n",
    "    losses.append(loss)\n",
    "    \n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    # Determine status\n",
    "    if epoch == 0:\n",
    "        status = \"Starting\"\n",
    "    elif loss < losses[-2]:\n",
    "        status = \"Improving\"\n",
    "    else:\n",
    "        status = \"Plateau\"\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"{epoch+1:>6} | {loss:>8.4f} | {lr:>10.6f} | {status}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"Best loss: {min(losses):.4f} (epoch {losses.index(min(losses))+1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss over epochs\n",
    "axes[0].plot(range(1, len(losses)+1), losses, 'b-', marker='o', markersize=4, linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Contrastive Loss')\n",
    "axes[0].set_title('Training Loss Over Time')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add reference lines\n",
    "initial_expected = np.log(2 * batch_size - 1)\n",
    "axes[0].axhline(initial_expected, color='gray', linestyle='--', alpha=0.5, \n",
    "               label=f'Random baseline: {initial_expected:.2f}')\n",
    "axes[0].axhline(3.0, color='green', linestyle='--', alpha=0.5, \n",
    "               label='Good target: 3.0')\n",
    "axes[0].legend()\n",
    "\n",
    "# Loss improvement\n",
    "improvement = [(losses[0] - l) / losses[0] * 100 for l in losses]\n",
    "axes[1].bar(range(1, len(losses)+1), improvement, color='steelblue', edgecolor='black')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Improvement from Initial (%)')\n",
    "axes[1].set_title('Cumulative Training Progress')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Initial loss: {losses[0]:.4f}\")\n",
    "print(f\"  Final loss: {losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {(1 - losses[-1]/losses[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### How to read the training curves\n\n**Left (Loss over time)**:\n- **Gray dashed line (random baseline)**: Expected loss if embeddings were random. Loss should start near here.\n- **Green dashed line (target)**: Good contrastive models reach loss ~3.0 or below.\n- **Blue curve**: Should decrease steadily. Plateaus are normal toward the end.\n- **If loss doesn't decrease**: Learning rate may be too high/low, or augmentation too aggressive.\n\n**Right (Improvement %)**:\n- Shows cumulative improvement from initial loss\n- Expect 30-50% improvement for well-trained models\n- Diminishing returns after ~10 epochs is normal",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Embeddings\n",
    "\n",
    "Use the trained model to create embeddings for all records.\n",
    "\n",
    "**What you should expect:**\n",
    "- Embeddings shape: `(N, 128)` - one 128-dim vector per event\n",
    "- Values roughly centered around 0\n",
    "- Similar events should have similar embeddings (high cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_embeddings(model, numerical, categorical, batch_size=512):\n",
    "    \"\"\"\n",
    "    Extract embeddings for all records.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings (N, d_model)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    \n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(numerical, dtype=torch.float32),\n",
    "        torch.tensor(categorical, dtype=torch.long)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    for num_batch, cat_batch in loader:\n",
    "        num_batch = num_batch.to(device)\n",
    "        cat_batch = cat_batch.to(device)\n",
    "        \n",
    "        emb = model(num_batch, cat_batch)\n",
    "        embeddings.append(emb.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# Extract embeddings\n",
    "print(\"Extracting embeddings...\")\n",
    "embeddings = extract_embeddings(model, numerical, categorical)\n",
    "\n",
    "print(f\"\\nEmbedding Statistics:\")\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"  Std: {embeddings.std():.4f}\")\n",
    "print(f\"  Min: {embeddings.min():.4f}\")\n",
    "print(f\"  Max: {embeddings.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Distribution of all values\n",
    "axes[0].hist(embeddings.flatten(), bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0].set_xlabel('Embedding Value')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Distribution of All Embedding Values')\n",
    "\n",
    "# Distribution of embedding norms\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "axes[1].hist(norms, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].set_xlabel('Embedding Norm (L2)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Distribution of Embedding Norms')\n",
    "axes[1].annotate(f'Mean: {norms.mean():.2f}\\nStd: {norms.std():.2f}', \n",
    "                xy=(0.7, 0.8), xycoords='axes fraction')\n",
    "\n",
    "# Sample embedding dimensions\n",
    "for i in range(5):\n",
    "    axes[2].hist(embeddings[:, i], bins=50, alpha=0.5, label=f'dim {i}')\n",
    "axes[2].set_xlabel('Value')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Sample Dimension Distributions')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### How to read the embedding distributions\n\n**Left (All embedding values)**:\n- Should be roughly centered around 0 (red dashed line)\n- Approximately symmetric distribution is healthy\n- Very long tails may indicate outlier events\n\n**Center (Embedding norms)**:\n- L2 norm = \"length\" of the embedding vector\n- Tight distribution = consistent embedding magnitudes (good)\n- Wide spread or outliers = some events produce unusual embeddings (potential anomalies)\n\n**Right (Individual dimensions)**:\n- Shows 5 sample dimensions overlaid\n- Different dimensions capture different patterns\n- Highly similar distributions = dimensions may be redundant",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings and model\n",
    "np.save('../data/embeddings.npy', embeddings)\n",
    "torch.save(model.state_dict(), '../data/tabular_resnet.pt')\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"  - ../data/embeddings.npy: {embeddings.shape}\")\n",
    "print(f\"  - ../data/tabular_resnet.pt: model weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Embedding Visualization\n",
    "\n",
    "Use t-SNE to visualize the learned embedding space in 2D.\n",
    "\n",
    "**What you should expect:**\n",
    "- Clusters should form (similar events group together)\n",
    "- Spread indicates diversity in the data\n",
    "- Isolated points may be anomalies\n",
    "\n",
    "**If you see a single blob:**\n",
    "- Model may need more training\n",
    "- Try different perplexity values (15, 30, 50)\n",
    "- Data may be very homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample for visualization (t-SNE is slow on large datasets)\n",
    "sample_size = min(2000, len(embeddings))\n",
    "indices = np.random.choice(len(embeddings), sample_size, replace=False)\n",
    "emb_sample = embeddings[indices]\n",
    "\n",
    "# Run t-SNE\n",
    "print(f\"Running t-SNE on {sample_size} samples (this may take 1-2 minutes)...\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "emb_2d = tsne.fit_transform(emb_sample)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Basic scatter\n",
    "axes[0].scatter(emb_2d[:, 0], emb_2d[:, 1], alpha=0.5, s=10, c='steelblue')\n",
    "axes[0].set_xlabel('t-SNE 1')\n",
    "axes[0].set_ylabel('t-SNE 2')\n",
    "axes[0].set_title('OCSF Event Embeddings (t-SNE)')\n",
    "\n",
    "# Colored by embedding norm (potential anomaly indicator)\n",
    "norms_sample = np.linalg.norm(emb_sample, axis=1)\n",
    "scatter = axes[1].scatter(emb_2d[:, 0], emb_2d[:, 1], c=norms_sample, \n",
    "                          cmap='viridis', alpha=0.5, s=10)\n",
    "axes[1].set_xlabel('t-SNE 1')\n",
    "axes[1].set_ylabel('t-SNE 2')\n",
    "axes[1].set_title('Embeddings Colored by L2 Norm')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Embedding Norm')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Clusters = similar events (same activity type, status, etc.)\")\n",
    "print(\"- Isolated points = potentially unusual events\")\n",
    "print(\"- High norm (yellow) = events far from center (potential anomalies)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Loaded processed features** from the feature engineering notebook\n",
    "2. **Built TabularResNet** - categorical embeddings + residual blocks\n",
    "3. **Implemented contrastive learning** - SimCLR-style with tabular augmentation\n",
    "4. **Trained the model** on unlabeled OCSF data (self-supervised)\n",
    "5. **Extracted embeddings** for all records\n",
    "6. **Visualized** the embedding space with t-SNE\n",
    "\n",
    "**Key insight**: We learned meaningful representations from **unlabeled data** by training the model to recognize that augmented versions of the same event should have similar embeddings.\n",
    "\n",
    "**Output files:**\n",
    "- `embeddings.npy`: (N, 128) embedding vectors\n",
    "- `tabular_resnet.pt`: trained model weights\n",
    "\n",
    "**Next**: \n",
    "- [05-model-inference.ipynb](05-model-inference.ipynb) - Load and use the model for new data\n",
    "- [06-anomaly-detection.ipynb](06-anomaly-detection.ipynb) - Detect anomalies using embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}