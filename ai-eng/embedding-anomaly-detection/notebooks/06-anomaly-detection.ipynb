{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Anomaly Detection Methods\n",
    "\n",
    "Apply anomaly detection algorithms to OCSF embeddings.\n",
    "\n",
    "**What you'll learn:**\n",
    "1. Distance-based anomaly detection (k-NN)\n",
    "2. Density-based detection (Local Outlier Factor)\n",
    "3. Tree-based detection (Isolation Forest)\n",
    "4. Evaluating detection performance\n",
    "5. Ensemble methods for robust detection\n",
    "\n",
    "**Prerequisites:**\n",
    "- Embeddings from [04-self-supervised-training.ipynb](04-self-supervised-training.ipynb)\n",
    "- Labeled evaluation subset (optional, for evaluation)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concept: Embedding-Based Anomaly Detection\n",
    "\n",
    "With good embeddings, anomaly detection becomes a **geometry problem**:\n",
    "- Normal events cluster together (similar embeddings)\n",
    "- Anomalies are **far from** normal clusters (high distance)\n",
    "- Anomalies are in **low-density** regions (few neighbors)\n",
    "\n",
    "No need to train a separate classifier - just measure distances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For nicer plots\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Embeddings and Labels\n",
    "\n",
    "Load the embeddings from training and the labeled evaluation subset.\n",
    "\n",
    "**What you should expect:**\n",
    "- Embeddings: `(N, 128)` - one vector per OCSF event\n",
    "- Evaluation subset (optional): events with `is_anomaly` labels\n",
    "\n",
    "**If you see errors:**\n",
    "- `FileNotFoundError`: Run notebooks 03 and 04 first\n",
    "- Shape mismatch: Ensure embeddings match your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings = np.load('../data/embeddings.npy')\n",
    "print(f\"Embeddings loaded:\")\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  Memory: {embeddings.nbytes / 1024**2:.1f} MB\")\n",
    "\n",
    "# Load labeled evaluation subset (if available)\n",
    "try:\n",
    "    eval_df = pd.read_parquet('../data/ocsf_eval_subset.parquet')\n",
    "    print(f\"\\nEvaluation subset loaded:\")\n",
    "    print(f\"  Events: {len(eval_df)}\")\n",
    "    print(f\"  Anomaly rate: {eval_df['is_anomaly'].mean():.2%}\")\n",
    "    has_labels = True\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nNo labeled evaluation subset found.\")\n",
    "    print(\"  Will use unsupervised evaluation (method agreement).\")\n",
    "    print(\"  To get labels, generate data with anomaly scenarios.\")\n",
    "    has_labels = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. k-NN Distance-Based Detection\n",
    "\n",
    "**Idea**: Anomalies are far from their nearest neighbors.\n",
    "\n",
    "For each point:\n",
    "1. Find k nearest neighbors\n",
    "2. Compute average distance to neighbors\n",
    "3. High average distance = likely anomaly\n",
    "\n",
    "**What you should expect:**\n",
    "- Score distribution: Most events have low scores, tail has anomalies\n",
    "- Threshold at 95th percentile flags ~5% as anomalies\n",
    "- Scores are in [0, 2] for cosine distance (0=identical, 2=opposite)\n",
    "\n",
    "**If scores are all similar:**\n",
    "- Embeddings may not capture anomaly patterns well\n",
    "- Try different k values (10, 20, 50)\n",
    "- Check if embeddings are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_knn_distance(embeddings, k=20, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Detect anomalies using k-NN average distance.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: (N, d) array of embeddings\n",
    "        k: Number of neighbors\n",
    "        contamination: Expected anomaly proportion\n",
    "    \n",
    "    Returns:\n",
    "        predictions: 1 for anomaly, 0 for normal\n",
    "        scores: Average distance to k neighbors (higher = more anomalous)\n",
    "        threshold: Score threshold used\n",
    "    \"\"\"\n",
    "    # Fit k-NN model (+1 because point is its own neighbor)\n",
    "    nn = NearestNeighbors(n_neighbors=k+1, metric='cosine')\n",
    "    nn.fit(embeddings)\n",
    "    \n",
    "    # Get distances to k nearest neighbors\n",
    "    distances, _ = nn.kneighbors(embeddings)\n",
    "    \n",
    "    # Average distance (excluding self at index 0)\n",
    "    scores = distances[:, 1:].mean(axis=1)\n",
    "    \n",
    "    # Threshold at percentile\n",
    "    threshold = np.percentile(scores, 100 * (1 - contamination))\n",
    "    predictions = (scores > threshold).astype(int)\n",
    "    \n",
    "    return predictions, scores, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run k-NN detection\n",
    "knn_preds, knn_scores, knn_threshold = detect_anomalies_knn_distance(\n",
    "    embeddings, k=20, contamination=0.05\n",
    ")\n",
    "\n",
    "print(\"k-NN Distance Detection Results:\")\n",
    "print(f\"  k (neighbors): 20\")\n",
    "print(f\"  Contamination: 5%\")\n",
    "print(f\"  Threshold: {knn_threshold:.4f}\")\n",
    "print(f\"  Anomalies detected: {knn_preds.sum()} ({knn_preds.mean():.2%})\")\n",
    "print(f\"\\nScore Statistics:\")\n",
    "print(f\"  Min: {knn_scores.min():.4f}\")\n",
    "print(f\"  Median: {np.median(knn_scores):.4f}\")\n",
    "print(f\"  Max: {knn_scores.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize k-NN score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram of scores\n",
    "axes[0].hist(knn_scores, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "axes[0].axvline(knn_threshold, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Threshold: {knn_threshold:.4f}')\n",
    "axes[0].set_xlabel('Average k-NN Distance')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('k-NN Distance Score Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Annotate regions\n",
    "axes[0].axvspan(knn_threshold, knn_scores.max() * 1.1, alpha=0.2, color='red', label='Anomaly region')\n",
    "\n",
    "# Sorted scores (useful to see the tail)\n",
    "sorted_scores = np.sort(knn_scores)[::-1]\n",
    "axes[1].plot(sorted_scores, linewidth=1, color='steelblue')\n",
    "axes[1].axhline(knn_threshold, color='red', linestyle='--', linewidth=2, label='Threshold')\n",
    "axes[1].fill_between(range(len(sorted_scores)), sorted_scores, knn_threshold, \n",
    "                     where=sorted_scores > knn_threshold, alpha=0.3, color='red')\n",
    "axes[1].set_xlabel('Rank (sorted by score)')\n",
    "axes[1].set_ylabel('k-NN Distance Score')\n",
    "axes[1].set_title('Sorted Anomaly Scores (Area = Detected Anomalies)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Left plot: Most events cluster at low distance (normal)\")\n",
    "print(\"- Right tail beyond threshold = anomalies\")\n",
    "print(\"- If distribution is uniform: embeddings may not capture anomaly patterns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Local Outlier Factor (LOF)\n",
    "\n",
    "**Idea**: Anomalies are in regions of lower density than their neighbors.\n",
    "\n",
    "LOF compares the local density of a point to its neighbors:\n",
    "- LOF ≈ 1: Similar density to neighbors (normal)\n",
    "- LOF > 1: Lower density than neighbors (anomaly)\n",
    "\n",
    "**Advantage over k-NN distance**: LOF adapts to varying local densities. A point can be far from the main cluster but still normal if its local area has similar density.\n",
    "\n",
    "**What you should expect:**\n",
    "- LOF scores centered around 1 for normal events\n",
    "- Anomalies have LOF > 1 (often > 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_lof(embeddings, n_neighbors=20, contamination=0.05):\n",
    "    \"\"\"\n",
    "    Detect anomalies using Local Outlier Factor.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: (N, d) array of embeddings\n",
    "        n_neighbors: Number of neighbors for density estimation\n",
    "        contamination: Expected anomaly proportion\n",
    "    \n",
    "    Returns:\n",
    "        predictions: 1 for anomaly, 0 for normal\n",
    "        scores: Outlier factor (higher = more anomalous)\n",
    "    \"\"\"\n",
    "    lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=contamination)\n",
    "    lof_predictions = lof.fit_predict(embeddings)\n",
    "    \n",
    "    # Convert: LOF returns -1 for anomalies, 1 for normal\n",
    "    predictions = (lof_predictions == -1).astype(int)\n",
    "    \n",
    "    # Scores (negative_outlier_factor_ is more negative for anomalies)\n",
    "    # Flip so higher = more anomalous\n",
    "    scores = -lof.negative_outlier_factor_\n",
    "    \n",
    "    return predictions, scores\n",
    "\n",
    "# Run LOF detection\n",
    "lof_preds, lof_scores = detect_anomalies_lof(embeddings, n_neighbors=20, contamination=0.05)\n",
    "\n",
    "print(\"Local Outlier Factor (LOF) Detection Results:\")\n",
    "print(f\"  n_neighbors: 20\")\n",
    "print(f\"  Contamination: 5%\")\n",
    "print(f\"  Anomalies detected: {lof_preds.sum()} ({lof_preds.mean():.2%})\")\n",
    "print(f\"\\nLOF Score Statistics:\")\n",
    "print(f\"  Min: {lof_scores.min():.4f} (most normal)\")\n",
    "print(f\"  Median: {np.median(lof_scores):.4f}\")\n",
    "print(f\"  Max: {lof_scores.max():.4f} (most anomalous)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Isolation Forest\n",
    "\n",
    "**Idea**: Anomalies are easier to \"isolate\" with random splits.\n",
    "\n",
    "Build random trees that recursively split data:\n",
    "- Normal points require many splits to isolate (deep in tree)\n",
    "- Anomalies require few splits (shallow in tree)\n",
    "\n",
    "**Advantages**:\n",
    "- Very fast (O(n log n) training)\n",
    "- Works well in high dimensions\n",
    "- No distance metric needed\n",
    "\n",
    "**What you should expect:**\n",
    "- Scores in [-1, 0] range (sklearn convention)\n",
    "- More negative = more anomalous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_isolation_forest(embeddings, contamination=0.05, n_estimators=100):\n",
    "    \"\"\"\n",
    "    Detect anomalies using Isolation Forest.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: (N, d) array of embeddings\n",
    "        contamination: Expected anomaly proportion\n",
    "        n_estimators: Number of trees\n",
    "    \n",
    "    Returns:\n",
    "        predictions: 1 for anomaly, 0 for normal\n",
    "        scores: Anomaly score (higher = more anomalous)\n",
    "    \"\"\"\n",
    "    iso = IsolationForest(contamination=contamination, n_estimators=n_estimators, random_state=42)\n",
    "    iso_predictions = iso.fit_predict(embeddings)\n",
    "    \n",
    "    # Convert: Isolation Forest returns -1 for anomalies, 1 for normal\n",
    "    predictions = (iso_predictions == -1).astype(int)\n",
    "    \n",
    "    # Scores (score_samples returns negative values, more negative = more anomalous)\n",
    "    # Flip so higher = more anomalous\n",
    "    scores = -iso.score_samples(embeddings)\n",
    "    \n",
    "    return predictions, scores\n",
    "\n",
    "# Run Isolation Forest detection\n",
    "iso_preds, iso_scores = detect_anomalies_isolation_forest(embeddings, contamination=0.05)\n",
    "\n",
    "print(\"Isolation Forest Detection Results:\")\n",
    "print(f\"  n_estimators: 100\")\n",
    "print(f\"  Contamination: 5%\")\n",
    "print(f\"  Anomalies detected: {iso_preds.sum()} ({iso_preds.mean():.2%})\")\n",
    "print(f\"\\nIsolation Score Statistics:\")\n",
    "print(f\"  Min: {iso_scores.min():.4f} (most normal)\")\n",
    "print(f\"  Median: {np.median(iso_scores):.4f}\")\n",
    "print(f\"  Max: {iso_scores.max():.4f} (most anomalous)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Detection Methods\n",
    "\n",
    "Different methods catch different types of anomalies:\n",
    "- **k-NN distance**: Global outliers (far from everything)\n",
    "- **LOF**: Local outliers (normal globally, anomalous locally)\n",
    "- **Isolation Forest**: Points that are easy to separate\n",
    "\n",
    "**What you should expect:**\n",
    "- Methods often agree on obvious anomalies (>80% agreement)\n",
    "- Disagreement on edge cases is normal\n",
    "- If labeled data available, compare precision/recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare score distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "methods = [\n",
    "    ('k-NN Distance', knn_scores, knn_preds),\n",
    "    ('LOF', lof_scores, lof_preds),\n",
    "    ('Isolation Forest', iso_scores, iso_preds)\n",
    "]\n",
    "\n",
    "for ax, (name, scores, preds) in zip(axes, methods):\n",
    "    # Plot normal vs anomaly score distributions\n",
    "    normal_scores = scores[preds == 0]\n",
    "    anomaly_scores = scores[preds == 1]\n",
    "    \n",
    "    ax.hist(normal_scores, bins=30, alpha=0.7, label=f'Normal (n={len(normal_scores)})', color='blue')\n",
    "    ax.hist(anomaly_scores, bins=30, alpha=0.7, label=f'Anomaly (n={len(anomaly_scores)})', color='red')\n",
    "    ax.set_xlabel('Anomaly Score')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Good separation between blue (normal) and red (anomaly) = method works well\")\n",
    "print(\"- Overlap = method is uncertain about those events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method agreement analysis\n",
    "print(\"Method Agreement Analysis:\")\n",
    "print(\"\\nPairwise Agreement (% of events classified the same):\")\n",
    "print(f\"  k-NN & LOF:        {(knn_preds == lof_preds).mean():.1%}\")\n",
    "print(f\"  k-NN & IsoForest:  {(knn_preds == iso_preds).mean():.1%}\")\n",
    "print(f\"  LOF & IsoForest:   {(lof_preds == iso_preds).mean():.1%}\")\n",
    "\n",
    "# Venn-style breakdown\n",
    "all_agree_anomaly = ((knn_preds == 1) & (lof_preds == 1) & (iso_preds == 1)).sum()\n",
    "all_agree_normal = ((knn_preds == 0) & (lof_preds == 0) & (iso_preds == 0)).sum()\n",
    "only_knn = ((knn_preds == 1) & (lof_preds == 0) & (iso_preds == 0)).sum()\n",
    "only_lof = ((knn_preds == 0) & (lof_preds == 1) & (iso_preds == 0)).sum()\n",
    "only_iso = ((knn_preds == 0) & (lof_preds == 0) & (iso_preds == 1)).sum()\n",
    "\n",
    "print(f\"\\nDetection Breakdown:\")\n",
    "print(f\"  All 3 agree (anomaly):  {all_agree_anomaly} events\")\n",
    "print(f\"  All 3 agree (normal):   {all_agree_normal} events\")\n",
    "print(f\"  Only k-NN detects:      {only_knn} events\")\n",
    "print(f\"  Only LOF detects:       {only_lof} events\")\n",
    "print(f\"  Only IsoForest detects: {only_iso} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate against labels if available\n",
    "def evaluate_detector(true_labels, predictions, scores, method_name):\n",
    "    \"\"\"Evaluate detection performance.\"\"\"\n",
    "    precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "    recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, scores)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'Method': method_name,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'AUC': auc\n",
    "    }\n",
    "\n",
    "if has_labels:\n",
    "    print(\"Evaluating against labeled data...\\n\")\n",
    "    \n",
    "    n_eval = min(len(eval_df), len(embeddings))\n",
    "    \n",
    "    if 'is_anomaly' in eval_df.columns:\n",
    "        true_labels = eval_df['is_anomaly'].values[:n_eval]\n",
    "        \n",
    "        results = []\n",
    "        results.append(evaluate_detector(true_labels, knn_preds[:n_eval], knn_scores[:n_eval], 'k-NN Distance'))\n",
    "        results.append(evaluate_detector(true_labels, lof_preds[:n_eval], lof_scores[:n_eval], 'LOF'))\n",
    "        results.append(evaluate_detector(true_labels, iso_preds[:n_eval], iso_scores[:n_eval], 'Isolation Forest'))\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(\"Method Comparison:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "        print(\"\\nInterpretation:\")\n",
    "        print(\"- Precision: % of detected anomalies that are true anomalies\")\n",
    "        print(\"- Recall: % of true anomalies that were detected\")\n",
    "        print(\"- F1: Harmonic mean of precision and recall\")\n",
    "        print(\"- AUC: Overall ranking quality (1.0 = perfect)\")\n",
    "else:\n",
    "    print(\"No labels available for evaluation.\")\n",
    "    print(\"Using method agreement as a proxy for confidence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ensemble Detection\n",
    "\n",
    "Combine multiple methods for more robust detection.\n",
    "\n",
    "**Strategy**: Flag as anomaly if ≥ 2 out of 3 methods agree.\n",
    "\n",
    "**Benefits**:\n",
    "- Reduces false positives (need multiple methods to agree)\n",
    "- Catches different anomaly types (each method has strengths)\n",
    "- More reliable for alerting systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_detection(predictions_list, threshold=2):\n",
    "    \"\"\"\n",
    "    Ensemble detection: flag as anomaly if >= threshold methods agree.\n",
    "    \n",
    "    Args:\n",
    "        predictions_list: List of prediction arrays\n",
    "        threshold: Minimum votes needed to flag as anomaly\n",
    "    \n",
    "    Returns:\n",
    "        predictions: 1 for anomaly, 0 for normal\n",
    "    \"\"\"\n",
    "    votes = np.sum(predictions_list, axis=0)\n",
    "    return (votes >= threshold).astype(int)\n",
    "\n",
    "# Combine all three methods\n",
    "ensemble_preds = ensemble_detection([knn_preds, lof_preds, iso_preds], threshold=2)\n",
    "\n",
    "print(\"Ensemble Detection (2/3 agreement):\")\n",
    "print(f\"  Anomalies detected: {ensemble_preds.sum()} ({ensemble_preds.mean():.2%})\")\n",
    "\n",
    "# Compare to individual methods\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  k-NN alone:      {knn_preds.sum()} anomalies\")\n",
    "print(f\"  LOF alone:       {lof_preds.sum()} anomalies\")\n",
    "print(f\"  IsoForest alone: {iso_preds.sum()} anomalies\")\n",
    "print(f\"  Ensemble (2/3):  {ensemble_preds.sum()} anomalies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ensemble voting\n",
    "votes = knn_preds + lof_preds + iso_preds\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Vote distribution\n",
    "vote_counts = [np.sum(votes == i) for i in range(4)]\n",
    "colors = ['green', 'lightgreen', 'orange', 'red']\n",
    "bars = axes[0].bar(['0 (Normal)', '1 (Maybe)', '2 (Likely)', '3 (Certain)'], \n",
    "                  vote_counts, color=colors, edgecolor='black')\n",
    "axes[0].set_xlabel('Number of Methods Flagging as Anomaly')\n",
    "axes[0].set_ylabel('Number of Events')\n",
    "axes[0].set_title('Ensemble Vote Distribution')\n",
    "for bar, count in zip(bars, vote_counts):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "                str(count), ha='center', va='bottom')\n",
    "\n",
    "# Score correlation between methods\n",
    "axes[1].scatter(knn_scores, iso_scores, c=lof_scores, cmap='RdYlGn_r', \n",
    "               alpha=0.5, s=10)\n",
    "axes[1].set_xlabel('k-NN Distance Score')\n",
    "axes[1].set_ylabel('Isolation Forest Score')\n",
    "axes[1].set_title('Score Correlation (color = LOF score)')\n",
    "plt.colorbar(axes[1].collections[0], ax=axes[1], label='LOF Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"- Events with 3 votes are high-confidence anomalies\")\n",
    "print(\"- Events with 0 votes are high-confidence normal\")\n",
    "print(\"- 1-2 votes indicate edge cases or method-specific anomalies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inspect Top Anomalies\n",
    "\n",
    "Look at the events with highest anomaly scores to understand what the model is catching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data for inspection\n",
    "df = pd.read_parquet('../data/ocsf_logs.parquet')\n",
    "\n",
    "# Add anomaly scores (match lengths)\n",
    "df = df.iloc[:len(knn_scores)].copy()\n",
    "df['knn_score'] = knn_scores[:len(df)]\n",
    "df['lof_score'] = lof_scores[:len(df)]\n",
    "df['iso_score'] = iso_scores[:len(df)]\n",
    "df['ensemble_anomaly'] = ensemble_preds[:len(df)]\n",
    "df['vote_count'] = votes[:len(df)]\n",
    "\n",
    "print(f\"Added anomaly scores to {len(df)} events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top anomalies by ensemble (all 3 methods agree)\n",
    "high_confidence_anomalies = df[df['vote_count'] == 3].nlargest(10, 'knn_score')\n",
    "\n",
    "print(f\"Top 10 High-Confidence Anomalies (all 3 methods agree):\")\n",
    "print(f\"Found {len(df[df['vote_count'] == 3])} total events with 3/3 votes\\n\")\n",
    "\n",
    "# Select display columns\n",
    "display_cols = ['activity_name', 'status', 'actor_user_name', 'http_response_code', \n",
    "                'knn_score', 'lof_score', 'iso_score']\n",
    "display_cols = [c for c in display_cols if c in high_confidence_anomalies.columns]\n",
    "\n",
    "if len(high_confidence_anomalies) > 0:\n",
    "    high_confidence_anomalies[display_cols].round(4)\n",
    "else:\n",
    "    print(\"No events flagged by all 3 methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what makes these events anomalous\n",
    "anomalies = df[df['ensemble_anomaly'] == 1]\n",
    "normals = df[df['ensemble_anomaly'] == 0]\n",
    "\n",
    "print(\"Anomaly vs Normal Comparison:\")\n",
    "print(\"\\nActivity Distribution:\")\n",
    "if 'activity_name' in df.columns:\n",
    "    print(\"\\nAnomalies:\")\n",
    "    print(anomalies['activity_name'].value_counts().head())\n",
    "    print(\"\\nNormals:\")\n",
    "    print(normals['activity_name'].value_counts().head())\n",
    "\n",
    "print(\"\\nStatus Distribution:\")\n",
    "if 'status' in df.columns:\n",
    "    print(\"\\nAnomalies:\")\n",
    "    print(anomalies['status'].value_counts())\n",
    "    print(\"\\nNormals:\")\n",
    "    print(normals['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results\n",
    "\n",
    "Save anomaly predictions for further analysis or integration with alerting systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save anomaly predictions\n",
    "results = pd.DataFrame({\n",
    "    'knn_score': knn_scores,\n",
    "    'knn_anomaly': knn_preds,\n",
    "    'lof_score': lof_scores,\n",
    "    'lof_anomaly': lof_preds,\n",
    "    'iso_score': iso_scores,\n",
    "    'iso_anomaly': iso_preds,\n",
    "    'ensemble_anomaly': ensemble_preds,\n",
    "    'vote_count': votes\n",
    "})\n",
    "\n",
    "results.to_parquet('../data/anomaly_predictions.parquet')\n",
    "print(f\"Saved anomaly predictions to ../data/anomaly_predictions.parquet\")\n",
    "print(f\"  Shape: {results.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total events analyzed: {len(embeddings):,}\")\n",
    "print(f\"\\nDetection Results:\")\n",
    "print(f\"  k-NN Distance:     {knn_preds.sum():,} anomalies ({knn_preds.mean():.1%})\")\n",
    "print(f\"  LOF:               {lof_preds.sum():,} anomalies ({lof_preds.mean():.1%})\")\n",
    "print(f\"  Isolation Forest:  {iso_preds.sum():,} anomalies ({iso_preds.mean():.1%})\")\n",
    "print(f\"  Ensemble (2/3):    {ensemble_preds.sum():,} anomalies ({ensemble_preds.mean():.1%})\")\n",
    "print(f\"\\nConfidence Levels:\")\n",
    "print(f\"  High (3/3 votes):  {(votes == 3).sum():,} events\")\n",
    "print(f\"  Medium (2/3 votes): {(votes == 2).sum():,} events\")\n",
    "print(f\"  Low (1/3 votes):   {(votes == 1).sum():,} events\")\n",
    "print(f\"  Normal (0/3 votes): {(votes == 0).sum():,} events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **k-NN Distance**: Detected anomalies based on average distance to neighbors\n",
    "2. **LOF**: Used local density comparison for adaptive detection\n",
    "3. **Isolation Forest**: Leveraged tree-based isolation for anomaly scoring\n",
    "4. **Ensemble**: Combined methods for robust detection with voting\n",
    "5. **Analyzed**: Compared methods and inspected top anomalies\n",
    "\n",
    "**Key insights:**\n",
    "- Different methods catch different types of anomalies\n",
    "- Ensemble voting (2/3 agreement) reduces false positives\n",
    "- High-confidence anomalies (3/3 votes) deserve immediate attention\n",
    "- LOF adapts to varying local densities (good for multi-modal data)\n",
    "- k-NN distance is simple but effective for global outliers\n",
    "\n",
    "**Production recommendations:**\n",
    "- Use **ensemble** for alerting (fewer false positives)\n",
    "- Use **k-NN scores** for ranking (continuous severity)\n",
    "- Tune `contamination` based on your expected anomaly rate\n",
    "- Consider using a **vector database** (FAISS, Milvus) for efficient k-NN at scale\n",
    "\n",
    "**Next steps:**\n",
    "- Integrate with alerting system\n",
    "- Set up monitoring for embedding drift\n",
    "- Collect feedback on detected anomalies for model improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
