{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Appendix: Model Saving and Inference\n\n> **Theory**: See [Part 5: Evaluating Embedding Quality](../part5-embedding-quality.md) for understanding how to assess embedding performance.\n\nSave trained models and use them for inference on new OCSF data.\n\n**What you'll learn:**\n1. Save trained TabularResNet models properly\n2. Load models for inference\n3. Process new OCSF events through the pipeline\n4. Generate embeddings for new data\n5. Common issues and troubleshooting\n\n**Prerequisites:**\n- Trained model from [04-self-supervised-training.ipynb](04-self-supervised-training.ipynb)\n- Feature artifacts from [03-feature-engineering.ipynb](03-feature-engineering.ipynb)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Architecture (for reference)\n",
    "\n",
    "We need the model class definition to load saved weights. This is the same architecture from the training notebook.\n",
    "\n",
    "**Important**: When loading a model, you must have access to the same class definition used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with two linear layers and skip connection.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_model)\n",
    "        self.linear2 = nn.Linear(d_model, d_model)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x = F.gelu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class TabularResNet(nn.Module):\n",
    "    \"\"\"ResNet-style architecture for tabular data.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_numerical, cardinalities, d_model=128, \n",
    "                 num_blocks=4, embedding_dim=32, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_numerical = num_numerical\n",
    "        self.cardinalities = cardinalities\n",
    "        \n",
    "        # Categorical embeddings\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(cardinality, embedding_dim)\n",
    "            for cardinality in cardinalities\n",
    "        ])\n",
    "        \n",
    "        # Calculate input dimension\n",
    "        total_cat_dim = len(cardinalities) * embedding_dim\n",
    "        input_dim = num_numerical + total_cat_dim\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_projection = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Residual blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(d_model, dropout) \n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Final layer norm\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, numerical, categorical, return_embedding=True):\n",
    "        # Embed categorical features\n",
    "        cat_embedded = []\n",
    "        for i, emb_layer in enumerate(self.embeddings):\n",
    "            cat_embedded.append(emb_layer(categorical[:, i]))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        if cat_embedded:\n",
    "            cat_concat = torch.cat(cat_embedded, dim=1)\n",
    "            x = torch.cat([numerical, cat_concat], dim=1)\n",
    "        else:\n",
    "            x = numerical\n",
    "        \n",
    "        # Project to model dimension\n",
    "        x = self.input_projection(x)\n",
    "        \n",
    "        # Apply residual blocks\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # Final normalization\n",
    "        x = self.final_norm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"Model class defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Feature Artifacts\n",
    "\n",
    "Before loading the model, we need the feature engineering artifacts:\n",
    "- **Encoders**: LabelEncoders for categorical columns\n",
    "- **Scaler**: StandardScaler for numerical columns\n",
    "- **Cardinalities**: Vocabulary sizes for embeddings\n",
    "\n",
    "**What you should expect:** The artifacts file contains all preprocessing objects needed to transform new data the same way as training data.\n",
    "\n",
    "**If you see errors here:**\n",
    "- `FileNotFoundError`: Run notebook 03 first to generate artifacts\n",
    "- `ModuleNotFoundError`: Ensure sklearn is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature artifacts\n",
    "with open('../data/feature_artifacts.pkl', 'rb') as f:\n",
    "    artifacts = pickle.load(f)\n",
    "\n",
    "encoders = artifacts['encoders']\n",
    "scaler = artifacts['scaler']\n",
    "categorical_cols = artifacts['categorical_cols']\n",
    "numerical_cols = artifacts['numerical_cols']\n",
    "cardinalities = artifacts['cardinalities']\n",
    "\n",
    "print(\"Feature Artifacts Loaded:\")\n",
    "print(f\"  Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"  Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"  Cardinalities: {cardinalities}\")\n",
    "print(f\"\\nScaler statistics (first 3 numerical features):\")\n",
    "for i, col in enumerate(numerical_cols[:3]):\n",
    "    print(f\"  {col}: mean={scaler.mean_[i]:.4f}, std={scaler.scale_[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Load Trained Model\n\nLoad the model weights saved during training.\n\n**Two approaches to saving PyTorch models:**\n1. `torch.save(model.state_dict(), path)` - Saves only weights (recommended)\n2. `torch.save(model, path)` - Saves entire model (less portable)\n\nWe use approach 1, so we need to:\n1. Create a new model instance with same architecture\n2. Load the saved weights\n\n**PyTorch 2.6+ Note:** PyTorch changed the default `weights_only` parameter from `False` to `True` for security. Since our saved files contain sklearn objects (LabelEncoder, StandardScaler), we must use `weights_only=False`. Only do this with files you trust.\n\n**What you should expect:** Model loads with matching parameter count.\n\n**If you see errors:**\n- `FileNotFoundError`: Run notebook 04 first to train and save the model\n- `RuntimeError: size mismatch`: Architecture parameters don't match saved weights\n- `UnpicklingError`: Add `weights_only=False` to torch.load()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create model with same architecture as training\nmodel = TabularResNet(\n    num_numerical=len(numerical_cols),\n    cardinalities=cardinalities,\n    d_model=128,\n    num_blocks=4,\n    embedding_dim=32,\n    dropout=0.1\n)\n\n# Load trained weights\n# Note: weights_only=False is needed because the package contains sklearn objects\nmodel.load_state_dict(torch.load('../data/tabular_resnet.pt', map_location=device, weights_only=False))\nmodel = model.to(device)\nmodel.eval()  # Set to evaluation mode (disables dropout)\n\nprint(\"Model loaded successfully!\")\nprint(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"  Device: {device}\")\nprint(f\"  Mode: Evaluation (dropout disabled)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Create Inference Pipeline\n\nBuild a complete pipeline that takes raw OCSF events and produces embeddings.\n\nThe pipeline handles:\n1. **Temporal features**: Extract hour, day, cyclical encoding\n2. **Missing values**: Fill with 'MISSING' or 0\n3. **Numeric categoricals**: Convert values like `http_response_code` (200, 404, 500) to strings for categorical encoding\n4. **Unknown categories**: Map to 'UNKNOWN' (added during training)\n5. **Scaling**: Apply saved StandardScaler\n6. **Encoding**: Apply saved LabelEncoders"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCSFEmbeddingPipeline:\n",
    "    \"\"\"\n",
    "    End-to-end pipeline for generating embeddings from raw OCSF events.\n",
    "    \n",
    "    Usage:\n",
    "        pipeline = OCSFEmbeddingPipeline(model, artifacts)\n",
    "        embeddings = pipeline.transform(new_ocsf_events_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, artifacts, device='cpu'):\n",
    "        self.model = model\n",
    "        self.encoders = artifacts['encoders']\n",
    "        self.scaler = artifacts['scaler']\n",
    "        self.categorical_cols = artifacts['categorical_cols']\n",
    "        self.numerical_cols = artifacts['numerical_cols']\n",
    "        self.cardinalities = artifacts['cardinalities']\n",
    "        self.device = device\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def extract_temporal_features(self, df):\n",
    "        \"\"\"Extract temporal features from Unix timestamp.\"\"\"\n",
    "        result = df.copy()\n",
    "        \n",
    "        if 'time' in result.columns:\n",
    "            result['datetime'] = pd.to_datetime(result['time'], unit='ms', errors='coerce')\n",
    "            result['hour_of_day'] = result['datetime'].dt.hour.fillna(12)\n",
    "            result['day_of_week'] = result['datetime'].dt.dayofweek.fillna(0)\n",
    "            result['is_weekend'] = (result['day_of_week'] >= 5).astype(int)\n",
    "            result['is_business_hours'] = ((result['hour_of_day'] >= 9) & \n",
    "                                           (result['hour_of_day'] < 17)).astype(int)\n",
    "            result['hour_sin'] = np.sin(2 * np.pi * result['hour_of_day'] / 24)\n",
    "            result['hour_cos'] = np.cos(2 * np.pi * result['hour_of_day'] / 24)\n",
    "            result['day_sin'] = np.sin(2 * np.pi * result['day_of_week'] / 7)\n",
    "            result['day_cos'] = np.cos(2 * np.pi * result['day_of_week'] / 7)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def preprocess(self, df):\n",
    "        \"\"\"Preprocess raw OCSF data for model input.\"\"\"\n",
    "        result = self.extract_temporal_features(df)\n",
    "        \n",
    "        # Handle categorical columns\n",
    "        for col in self.categorical_cols:\n",
    "            if col in result.columns:\n",
    "                result[col] = result[col].fillna('MISSING').astype(str)\n",
    "                result[col] = result[col].replace('', 'MISSING')\n",
    "            else:\n",
    "                result[col] = 'MISSING'\n",
    "        \n",
    "        # Handle numerical columns\n",
    "        for col in self.numerical_cols:\n",
    "            if col in result.columns:\n",
    "                result[col] = pd.to_numeric(result[col], errors='coerce').fillna(0)\n",
    "            else:\n",
    "                result[col] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def encode_features(self, df):\n",
    "        \"\"\"Encode features using saved encoders and scaler.\"\"\"\n",
    "        # Encode categorical features (handle unknown values)\n",
    "        categorical_data = []\n",
    "        for col in self.categorical_cols:\n",
    "            encoder = self.encoders[col]\n",
    "            values = df[col].values\n",
    "            \n",
    "            # Map unknown values to 'UNKNOWN'\n",
    "            known_classes = set(encoder.classes_)\n",
    "            values = np.array([v if v in known_classes else 'UNKNOWN' for v in values])\n",
    "            \n",
    "            encoded = encoder.transform(values)\n",
    "            categorical_data.append(encoded)\n",
    "        \n",
    "        categorical_array = np.column_stack(categorical_data)\n",
    "        \n",
    "        # Scale numerical features\n",
    "        numerical_array = self.scaler.transform(df[self.numerical_cols])\n",
    "        \n",
    "        return numerical_array, categorical_array\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def transform(self, df, batch_size=512):\n",
    "        \"\"\"\n",
    "        Transform raw OCSF events to embeddings.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with OCSF events\n",
    "            batch_size: Batch size for inference\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of embeddings (N, d_model)\n",
    "        \"\"\"\n",
    "        # Preprocess\n",
    "        processed = self.preprocess(df)\n",
    "        \n",
    "        # Encode\n",
    "        numerical, categorical = self.encode_features(processed)\n",
    "        \n",
    "        # Create tensors\n",
    "        num_tensor = torch.tensor(numerical, dtype=torch.float32)\n",
    "        cat_tensor = torch.tensor(categorical, dtype=torch.long)\n",
    "        \n",
    "        # Generate embeddings in batches\n",
    "        embeddings = []\n",
    "        dataset = TensorDataset(num_tensor, cat_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        for num_batch, cat_batch in loader:\n",
    "            num_batch = num_batch.to(self.device)\n",
    "            cat_batch = cat_batch.to(self.device)\n",
    "            \n",
    "            emb = self.model(num_batch, cat_batch)\n",
    "            embeddings.append(emb.cpu().numpy())\n",
    "        \n",
    "        return np.vstack(embeddings)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = OCSFEmbeddingPipeline(model, artifacts, device=device)\n",
    "print(\"Inference pipeline created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test on Sample Data\n",
    "\n",
    "Let's verify the pipeline works by generating embeddings for the original training data.\n",
    "\n",
    "**What you should expect:**\n",
    "- Embeddings should be 128-dimensional (d_model=128)\n",
    "- Values should be roughly centered around 0 with moderate variance\n",
    "- Processing should complete without errors\n",
    "\n",
    "**If you see issues:**\n",
    "- Very large values (>10): Model may not have trained properly\n",
    "- All zeros: Check model loading and device placement\n",
    "- NaN values: Check for missing columns in input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original data\n",
    "df = pd.read_parquet('../data/ocsf_logs.parquet')\n",
    "print(f\"Loaded {len(df)} OCSF events\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "embeddings = pipeline.transform(df)\n",
    "\n",
    "print(f\"\\nEmbedding Results:\")\n",
    "print(f\"  Shape: {embeddings.shape}\")\n",
    "print(f\"  Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"  Std: {embeddings.std():.4f}\")\n",
    "print(f\"  Min: {embeddings.min():.4f}\")\n",
    "print(f\"  Max: {embeddings.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with pre-computed embeddings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "original_embeddings = np.load('../data/embeddings.npy')\n",
    "\n",
    "# Check if they match\n",
    "max_diff = np.abs(embeddings - original_embeddings).max()\n",
    "mean_diff = np.abs(embeddings - original_embeddings).mean()\n",
    "\n",
    "print(\"Comparison with saved embeddings:\")\n",
    "print(f\"  Max absolute difference: {max_diff:.6f}\")\n",
    "print(f\"  Mean absolute difference: {mean_diff:.6f}\")\n",
    "\n",
    "if max_diff < 1e-4:\n",
    "    print(\"  ✓ Embeddings match! Pipeline is working correctly.\")\n",
    "else:\n",
    "    print(\"  ⚠ Embeddings differ slightly (this can happen with different device/precision)\")\n",
    "\n",
    "# Visualize a few embedding dimensions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.scatter(original_embeddings[:, i], embeddings[:, i], alpha=0.3, s=5)\n",
    "    ax.plot([-3, 3], [-3, 3], 'r--', linewidth=2, label='Perfect match')\n",
    "    ax.set_xlabel(f'Original dim {i}')\n",
    "    ax.set_ylabel(f'Recomputed dim {i}')\n",
    "    ax.set_title(f'Dimension {i} Comparison')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### How to read these comparison charts\n\nEach scatter plot compares one embedding dimension between the original (saved) and recomputed embeddings:\n\n- **Points on the red dashed line**: Perfect match between original and recomputed\n- **Points clustered tightly around the line**: Pipeline is working correctly\n- **Scattered points**: Something differs (device, precision, or code changes)\n\nA small amount of scatter (differences < 0.0001) is acceptable due to floating-point precision differences between devices.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process New Events\n",
    "\n",
    "Demonstrate processing completely new OCSF events that weren't in the training data.\n",
    "\n",
    "**Key consideration**: New events may contain categorical values not seen during training. The pipeline handles this by mapping unknown values to the 'UNKNOWN' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some synthetic new events\n",
    "new_events = pd.DataFrame([\n",
    "    {\n",
    "        'time': 1704067200000,  # Jan 1, 2024 00:00:00\n",
    "        'class_name': 'Web Resources Activity',\n",
    "        'activity_name': 'Access',\n",
    "        'status': 'Success',\n",
    "        'level': 'informational',\n",
    "        'service': 'api-gateway',\n",
    "        'actor_user_name': 'new_user_123',  # Unknown user\n",
    "        'http_request_method': 'GET',\n",
    "        'http_request_url_path': '/api/v1/data',\n",
    "        'severity_id': 1,\n",
    "        'activity_id': 1,\n",
    "        'status_id': 1,\n",
    "        'duration': 150,\n",
    "        'http_response_code': 200,\n",
    "    },\n",
    "    {\n",
    "        'time': 1704070800000,  # Jan 1, 2024 01:00:00 (1 AM - suspicious)\n",
    "        'class_name': 'Web Resources Activity',\n",
    "        'activity_name': 'Create',\n",
    "        'status': 'Success',\n",
    "        'level': 'informational',\n",
    "        'service': 'unknown-service',  # Unknown service\n",
    "        'actor_user_name': 'admin',\n",
    "        'http_request_method': 'POST',\n",
    "        'http_request_url_path': '/admin/users',\n",
    "        'severity_id': 2,\n",
    "        'activity_id': 2,\n",
    "        'status_id': 1,\n",
    "        'duration': 500,\n",
    "        'http_response_code': 201,\n",
    "    },\n",
    "    {\n",
    "        'time': 1704153600000,  # Jan 2, 2024 00:00:00\n",
    "        'class_name': 'Authentication',  # May be unknown class\n",
    "        'activity_name': 'Logon',\n",
    "        'status': 'Failure',\n",
    "        'level': 'warning',\n",
    "        'service': 'auth-service',\n",
    "        'actor_user_name': 'attacker',\n",
    "        'http_request_method': 'POST',\n",
    "        'http_request_url_path': '/login',\n",
    "        'severity_id': 3,\n",
    "        'activity_id': 1,\n",
    "        'status_id': 2,\n",
    "        'duration': 50,\n",
    "        'http_response_code': 401,\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"New events to process:\")\n",
    "print(new_events[['time', 'activity_name', 'status', 'actor_user_name', 'http_response_code']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for new events\n",
    "new_embeddings = pipeline.transform(new_events)\n",
    "\n",
    "print(f\"\\nNew Event Embeddings:\")\n",
    "print(f\"  Shape: {new_embeddings.shape}\")\n",
    "print(f\"\\nEmbedding statistics per event:\")\n",
    "for i, event in enumerate(['Normal API access', 'Suspicious 1AM admin', 'Failed auth']):\n",
    "    emb = new_embeddings[i]\n",
    "    print(f\"  {event}:\")\n",
    "    print(f\"    Mean: {emb.mean():.4f}, Std: {emb.std():.4f}, Norm: {np.linalg.norm(emb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find Similar Events\n",
    "\n",
    "Use embeddings to find similar events in the training data.\n",
    "\n",
    "**What you should expect:**\n",
    "- Similar events (same activity, status) should have high cosine similarity\n",
    "- Unusual events may have lower similarity to most training data\n",
    "- Cosine similarity ranges from -1 to 1 (higher = more similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def find_similar_events(query_embedding, reference_embeddings, reference_df, top_k=5):\n",
    "    \"\"\"\n",
    "    Find most similar events using cosine similarity.\n",
    "    \n",
    "    Returns indices and similarities of top-k matches.\n",
    "    \"\"\"\n",
    "    # Compute similarities\n",
    "    similarities = cosine_similarity([query_embedding], reference_embeddings)[0]\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    top_similarities = similarities[top_indices]\n",
    "    \n",
    "    return top_indices, top_similarities\n",
    "\n",
    "# Find similar events for each new event\n",
    "display_cols = ['activity_name', 'status', 'actor_user_name', 'http_response_code']\n",
    "display_cols = [c for c in display_cols if c in df.columns]\n",
    "\n",
    "print(\"Finding similar events in training data...\\n\")\n",
    "\n",
    "for i, (name, emb) in enumerate(zip(\n",
    "    ['Normal API access', 'Suspicious 1AM admin', 'Failed auth attempt'],\n",
    "    new_embeddings\n",
    ")):\n",
    "    indices, sims = find_similar_events(emb, original_embeddings, df, top_k=3)\n",
    "    \n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Query: {new_events.iloc[i][display_cols].to_dict()}\")\n",
    "    print(f\"\\nTop 3 similar events (cosine similarity):\")\n",
    "    for idx, sim in zip(indices, sims):\n",
    "        print(f\"  Similarity: {sim:.4f}\")\n",
    "        print(f\"    {df.iloc[idx][display_cols].to_dict()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Anomaly Scoring for New Events\n",
    "\n",
    "Score new events against the training distribution.\n",
    "\n",
    "**What you should expect:**\n",
    "- Normal events should have low anomaly scores (close to training data)\n",
    "- Unusual events (1 AM admin activity, failed auth) may have higher scores\n",
    "- Scores represent average distance to k-nearest training neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.neighbors import NearestNeighbors\n\n# Fit k-NN on training embeddings\nk = 20\nknn = NearestNeighbors(n_neighbors=k, metric='cosine')\nknn.fit(original_embeddings)\n\n# Score new events\ndistances, _ = knn.kneighbors(new_embeddings)\nanomaly_scores = distances.mean(axis=1)\n\n# Compare to training distribution\ntrain_distances, _ = knn.kneighbors(original_embeddings)\ntrain_scores = train_distances[:, 1:].mean(axis=1)  # Exclude self\n\nprint(\"Anomaly Scores (k-NN distance):\")\nprint(f\"\\nTraining data statistics:\")\nprint(f\"  Mean: {train_scores.mean():.4f}\")\nprint(f\"  Std: {train_scores.std():.4f}\")\nprint(f\"  95th percentile: {np.percentile(train_scores, 95):.4f}\")\n\nprint(f\"\\nNew event scores:\")\nfor name, score in zip(\n    ['Normal API access', 'Suspicious 1AM admin', 'Failed auth attempt'],\n    anomaly_scores\n):\n    percentile = (train_scores < score).mean() * 100\n    flag = \"⚠️ ANOMALY\" if percentile > 95 else \"✓ Normal\"\n    print(f\"  {name}: {score:.4f} (percentile: {percentile:.1f}%) {flag}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize where new events fall in the score distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Plot training distribution\n",
    "ax.hist(train_scores, bins=50, alpha=0.7, label='Training data', color='blue', edgecolor='black')\n",
    "\n",
    "# Mark 95th percentile threshold\n",
    "threshold = np.percentile(train_scores, 95)\n",
    "ax.axvline(threshold, color='red', linestyle='--', linewidth=2, label=f'95th percentile: {threshold:.4f}')\n",
    "\n",
    "# Mark new events\n",
    "colors = ['green', 'orange', 'red']\n",
    "names = ['Normal API', 'Suspicious 1AM', 'Failed auth']\n",
    "for score, color, name in zip(anomaly_scores, colors, names):\n",
    "    ax.axvline(score, color=color, linewidth=3, label=f'{name}: {score:.4f}')\n",
    "\n",
    "ax.set_xlabel('Anomaly Score (k-NN distance)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('New Event Scores vs Training Distribution')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### How to read this anomaly score chart\n\n- **Blue histogram**: Distribution of anomaly scores from training data (baseline)\n- **Red dashed line**: 95th percentile threshold - events beyond this are flagged as anomalies\n- **Colored vertical lines**: Where new events fall in the distribution\n\n**Interpretation**:\n- Lines **left of threshold** (in the blue bulk): Normal events\n- Lines **right of threshold** (in the tail): Anomalous events\n- The further right, the more anomalous the event appears relative to training data",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Pipeline for Production\n",
    "\n",
    "Save everything needed for production inference.\n",
    "\n",
    "**Production deployment checklist:**\n",
    "1. Model weights (`tabular_resnet.pt`)\n",
    "2. Feature artifacts (`feature_artifacts.pkl`)\n",
    "3. Model class definition (copy to your codebase)\n",
    "4. Training embeddings for anomaly scoring (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete inference package\n",
    "inference_package = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'num_numerical': len(numerical_cols),\n",
    "        'cardinalities': cardinalities,\n",
    "        'd_model': 128,\n",
    "        'num_blocks': 4,\n",
    "        'embedding_dim': 32,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "    'feature_artifacts': artifacts,\n",
    "    'training_stats': {\n",
    "        'anomaly_score_mean': train_scores.mean(),\n",
    "        'anomaly_score_std': train_scores.std(),\n",
    "        'anomaly_score_95pct': float(np.percentile(train_scores, 95)),\n",
    "        'training_samples': len(original_embeddings)\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(inference_package, '../data/inference_package.pt')\n",
    "print(\"Saved complete inference package to ../data/inference_package.pt\")\n",
    "print(\"\\nPackage contents:\")\n",
    "for key in inference_package:\n",
    "    if isinstance(inference_package[key], dict):\n",
    "        print(f\"  {key}: {list(inference_package[key].keys())}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {type(inference_package[key]).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Reference: Loading in Production\n",
    "\n",
    "Here's a minimal example of using the saved model in production:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Load and use in production\ndef load_production_model(package_path, device='cpu'):\n    \"\"\"\n    Load model from inference package.\n    \n    Usage:\n        model, pipeline, stats = load_production_model('inference_package.pt')\n        embeddings = pipeline.transform(new_events_df)\n    \"\"\"\n    # Note: weights_only=False is required because the package contains sklearn\n    # objects (LabelEncoder, StandardScaler). Only use this with trusted files.\n    package = torch.load(package_path, map_location=device, weights_only=False)\n    \n    # Recreate model\n    config = package['model_config']\n    model = TabularResNet(\n        num_numerical=config['num_numerical'],\n        cardinalities=config['cardinalities'],\n        d_model=config['d_model'],\n        num_blocks=config['num_blocks'],\n        embedding_dim=config['embedding_dim'],\n        dropout=config['dropout']\n    )\n    model.load_state_dict(package['model_state_dict'])\n    model = model.to(device)\n    model.eval()\n    \n    # Create pipeline\n    pipeline = OCSFEmbeddingPipeline(model, package['feature_artifacts'], device=device)\n    \n    return model, pipeline, package['training_stats']\n\n# Demo\nprint(\"Loading production model...\")\nprod_model, prod_pipeline, stats = load_production_model('../data/inference_package.pt', device=device)\n\nprint(f\"\\nModel loaded. Training statistics:\")\nprint(f\"  Training samples: {stats['training_samples']}\")\nprint(f\"  Anomaly threshold (95%): {stats['anomaly_score_95pct']:.4f}\")\n\n# Quick test\ntest_emb = prod_pipeline.transform(new_events[:1])\nprint(f\"\\nTest inference successful. Embedding shape: {test_emb.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. **Loaded trained model** and feature artifacts\n",
    "2. **Built inference pipeline** that handles the complete workflow\n",
    "3. **Verified reproducibility** by comparing with saved embeddings\n",
    "4. **Processed new events** including those with unknown categories\n",
    "5. **Found similar events** using cosine similarity\n",
    "6. **Computed anomaly scores** against training distribution\n",
    "7. **Saved production package** with model, config, and statistics\n",
    "\n",
    "**Key takeaways:**\n",
    "- Always save model config alongside weights\n",
    "- Include feature artifacts (encoders, scalers) for preprocessing\n",
    "- Handle unknown categorical values gracefully\n",
    "- Use training statistics for calibrating anomaly thresholds\n",
    "\n",
    "**Next**: Use the model for [anomaly detection](06-anomaly-detection.ipynb) on production data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}