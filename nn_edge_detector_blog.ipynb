{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Neural Networks Learn to See: Building an Edge Detector from Scratch\n",
    "\n",
    "*A hands-on guide to understanding how a single neuron detects patterns in images*\n",
    "\n",
    "---\n",
    "\n",
    "Have you ever wondered how neural networks can recognize faces, read handwriting, or detect objects in photos? It all starts with something surprisingly simple: **pattern matching**.\n",
    "\n",
    "In this post, we'll build an edge detector from scratch to understand the fundamental operation at the heart of all neural networks. By the end, you'll have an intuitive grasp of:\n",
    "\n",
    "- How a single neuron works (it's just multiplication and addition!)\n",
    "- Why **weights** determine what patterns a neuron responds to\n",
    "- How **ReLU activation** acts as a gate\n",
    "- Why **bias** matters for controlling sensitivity\n",
    "\n",
    "No prior deep learning knowledge required — just basic math intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Big Picture: What Does a Neuron Actually Do?\n",
    "\n",
    "A neuron in a neural network does three things:\n",
    "\n",
    "1. **Multiply** each input by a learned weight\n",
    "2. **Add** all the products together (plus a bias term)\n",
    "3. **Apply an activation function** (we'll use ReLU)\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$z = \\sum_{i} x_i \\cdot w_i + b = (x_1 \\cdot w_1) + (x_2 \\cdot w_2) + \\ldots + (x_n \\cdot w_n) + b$$\n",
    "\n",
    "$$\\text{output} = \\text{ReLU}(z) = \\max(0, z)$$\n",
    "\n",
    "That's it! The magic is in *what values the weights take* — they determine what pattern the neuron responds to.\n",
    "\n",
    "**Intuition:** Think of each input as an expert's opinion, and the weights as how much you trust each expert. A large positive weight means \"this input is very important.\" A negative weight means \"if this input is high, I'm *less* interested.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(inputs, weights, bias=0):\n",
    "    \"\"\"Compute the weighted sum: z = sum(x * w) + b\"\"\"\n",
    "    return np.sum(inputs * weights) + bias\n",
    "\n",
    "def relu(z):\n",
    "    \"\"\"ReLU activation: max(0, z)\"\"\"\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def neuron_output(inputs, weights, bias=0):\n",
    "    \"\"\"Complete neuron: weighted sum followed by ReLU\"\"\"\n",
    "    z = weighted_sum(inputs, weights, bias)\n",
    "    return relu(z), z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is ReLU and Why Do We Need It?\n",
    "\n",
    "**ReLU** (Rectified Linear Unit) is the simplest activation function:\n",
    "\n",
    "$$\\text{ReLU}(z) = \\max(0, z) = \\begin{cases} z & \\text{if } z > 0 \\\\ 0 & \\text{if } z \\leq 0 \\end{cases}$$\n",
    "\n",
    "It acts as a **gate**: positive signals pass through unchanged, negative signals get blocked.\n",
    "\n",
    "**Why is this useful?** Without an activation function, stacking layers would be pointless — the whole network would collapse into a single linear transformation. ReLU introduces *non-linearity*, which allows the network to learn complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y_relu = np.maximum(0, x)\n",
    "\n",
    "axes[0].plot(x, x, 'b--', alpha=0.5, label='Identity (no activation)')\n",
    "axes[0].plot(x, y_relu, 'r-', linewidth=2.5, label='ReLU')\n",
    "axes[0].axhline(y=0, color='black', linewidth=0.5)\n",
    "axes[0].axvline(x=0, color='black', linewidth=0.5)\n",
    "axes[0].fill_between(x[x<0], 0, x[x<0], alpha=0.2, color='red', label='Blocked region')\n",
    "axes[0].set_xlabel('Input (z)', fontsize=12)\n",
    "axes[0].set_ylabel('Output', fontsize=12)\n",
    "axes[0].set_title('ReLU: The Simplest Activation Function', fontsize=13)\n",
    "axes[0].legend()\n",
    "axes[0].set_xlim(-5, 5)\n",
    "axes[0].set_ylim(-2, 5)\n",
    "\n",
    "sample_z = [-2.5, -1, 0, 1, 2.5]\n",
    "sample_relu = [max(0, z) for z in sample_z]\n",
    "colors = ['#d62728' if z <= 0 else '#2ca02c' for z in sample_z]\n",
    "\n",
    "axes[1].bar(range(len(sample_z)), sample_relu, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_xticks(range(len(sample_z)))\n",
    "axes[1].set_xticklabels([f'z={z}' for z in sample_z])\n",
    "axes[1].set_ylabel('ReLU(z)', fontsize=12)\n",
    "axes[1].set_title('ReLU Blocks Negative Values', fontsize=13)\n",
    "\n",
    "for i, (z, out) in enumerate(zip(sample_z, sample_relu)):\n",
    "    label = f'{out}' if out > 0 else 'blocked!'\n",
    "    axes[1].annotate(label, (i, out + 0.15), ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Edge Detector\n",
    "\n",
    "Now let's see how a neuron can detect a specific pattern: a **vertical edge**.\n",
    "\n",
    "Imagine a tiny 5×5 grayscale image (25 pixels). A neuron connected to this image has:\n",
    "- **25 inputs** (one per pixel, values 0–1 where 0=black, 1=white)\n",
    "- **25 weights** (one per connection)\n",
    "- **1 output** (after weighted sum + ReLU)\n",
    "\n",
    "### Designing the Weights\n",
    "\n",
    "To detect a vertical edge (dark on left, bright on right), we set:\n",
    "- **Negative weights (-1)** on the left columns → \"I want darkness here\"\n",
    "- **Positive weights (+1)** on the right columns → \"I want brightness here\"\n",
    "- **Zero weights (0)** in the middle → \"I don't care about this region\"\n",
    "\n",
    "When an image with this exact pattern arrives, the positive and negative contributions reinforce each other, giving a high score. When the pattern doesn't match, contributions cancel out or go negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights = np.array([\n",
    "    [-1, -1, 0, +1, +1],\n",
    "    [-1, -1, 0, +1, +1],\n",
    "    [-1, -1, 0, +1, +1],\n",
    "    [-1, -1, 0, +1, +1],\n",
    "    [-1, -1, 0, +1, +1]\n",
    "], dtype=float)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "cmap = LinearSegmentedColormap.from_list('edge', ['#d62728', 'white', '#1f77b4'])\n",
    "im = ax.imshow(edge_weights, cmap=cmap, vmin=-1, vmax=1)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        ax.text(j, i, f'{edge_weights[i, j]:+.0f}', ha='center', va='center', fontsize=16, fontweight='bold')\n",
    "\n",
    "ax.set_xticks(range(5))\n",
    "ax.set_yticks(range(5))\n",
    "ax.set_title('Vertical Edge Detector Weights\\n(Red = -1 \"want dark\", Blue = +1 \"want bright\")', fontsize=13)\n",
    "plt.colorbar(im, ax=ax, label='Weight Value', shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Detector on Different Images\n",
    "\n",
    "Let's create several test images to see how our detector responds:\n",
    "\n",
    "| Image | Description | Expected Response |\n",
    "|-------|-------------|-------------------|\n",
    "| Perfect Edge | Dark left, bright right | **Strong** (pattern matches!) |\n",
    "| Shifted Edge | Edge in wrong position | **Reduced** (partial match) |\n",
    "| Uniform Gray | No edge at all | **Zero** (no contrast) |\n",
    "| Inverted Edge | Bright left, dark right | **Blocked** (opposite of what we want) |\n",
    "| Horizontal Edge | Edge rotates 90° | **Weak** (wrong orientation) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_edge = np.array([[0.1, 0.1, 0.5, 0.9, 0.9]] * 5)\n",
    "edge_shifted_left = np.array([[0.1, 0.5, 0.9, 0.9, 0.9]] * 5)\n",
    "edge_shifted_right = np.array([[0.1, 0.1, 0.1, 0.5, 0.9]] * 5)\n",
    "uniform_gray = np.full((5, 5), 0.5)\n",
    "inverted_edge = np.array([[0.9, 0.9, 0.5, 0.1, 0.1]] * 5)\n",
    "horizontal_edge = np.array([[0.1]*5, [0.1]*5, [0.5]*5, [0.9]*5, [0.9]*5])\n",
    "diagonal_edge = np.array([[0.1, 0.1, 0.1, 0.5, 0.9],\n",
    "                          [0.1, 0.1, 0.5, 0.9, 0.9],\n",
    "                          [0.1, 0.5, 0.9, 0.9, 0.9],\n",
    "                          [0.5, 0.9, 0.9, 0.9, 0.9],\n",
    "                          [0.9, 0.9, 0.9, 0.9, 0.9]])\n",
    "\n",
    "test_images = [\n",
    "    (\"Perfect Edge\", perfect_edge),\n",
    "    (\"Edge Shifted Left\", edge_shifted_left),\n",
    "    (\"Edge Shifted Right\", edge_shifted_right),\n",
    "    (\"Uniform Gray\", uniform_gray),\n",
    "    (\"Inverted Edge\", inverted_edge),\n",
    "    (\"Horizontal Edge\", horizontal_edge),\n",
    "    (\"Diagonal Edge\", diagonal_edge)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "cmap_weights = LinearSegmentedColormap.from_list('edge', ['#d62728', 'white', '#1f77b4'])\n",
    "axes[0].imshow(edge_weights, cmap=cmap_weights, vmin=-1, vmax=1)\n",
    "axes[0].set_title('DETECTOR\\nWEIGHTS', fontsize=12, fontweight='bold', color='#1f77b4')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[0].text(j, i, f'{edge_weights[i, j]:+.0f}', ha='center', va='center', fontsize=10)\n",
    "\n",
    "for idx, (name, img) in enumerate(test_images):\n",
    "    axes[idx + 1].imshow(img, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[idx + 1].set_title(name, fontsize=11)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.suptitle('Test Images for Our Edge Detector', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Neuron's Response\n",
    "\n",
    "For each image, we compute:\n",
    "\n",
    "$$z = \\sum_{i,j} \\text{image}[i,j] \\times \\text{weight}[i,j] + b$$\n",
    "\n",
    "$$\\text{output} = \\max(0, z)$$\n",
    "\n",
    "> **Note:** We're setting **bias $b = 0$** for now to keep things simple. This lets us focus purely on how the weight pattern matches the input. We'll explore bias later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_response(image, weights, name):\n",
    "    products = image * weights\n",
    "    z = np.sum(products)\n",
    "    output = max(0, z)\n",
    "    return {'name': name, 'image': image, 'products': products, 'weighted_sum': z, 'relu_output': output}\n",
    "\n",
    "results = [analyze_response(img, edge_weights, name) for name, img in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "names = [r['name'] for r in results]\n",
    "weighted_sums = [r['weighted_sum'] for r in results]\n",
    "relu_outputs = [r['relu_output'] for r in results]\n",
    "\n",
    "colors_ws = ['#2ca02c' if ws > 0 else '#d62728' for ws in weighted_sums]\n",
    "axes[0].barh(names, weighted_sums, color=colors_ws, alpha=0.8, edgecolor='black')\n",
    "axes[0].axvline(x=0, color='black', linewidth=2)\n",
    "axes[0].set_xlabel('Weighted Sum (z)', fontsize=12)\n",
    "axes[0].set_title('Step 1: Weighted Sum\\n(before ReLU)', fontsize=13, fontweight='bold')\n",
    "for i, v in enumerate(weighted_sums):\n",
    "    axes[0].text(v + (0.3 if v >= 0 else -0.8), i, f'{v:.1f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "colors_relu = ['#2ca02c' if o > 0 else '#999999' for o in relu_outputs]\n",
    "axes[1].barh(names, relu_outputs, color=colors_relu, alpha=0.8, edgecolor='black')\n",
    "axes[1].set_xlabel('Output', fontsize=12)\n",
    "axes[1].set_title('Step 2: After ReLU\\n(negative values blocked)', fontsize=13, fontweight='bold')\n",
    "for i, (v, ws) in enumerate(zip(relu_outputs, weighted_sums)):\n",
    "    label = f'{v:.1f}' if v > 0 else f'blocked (was {ws:.1f})'\n",
    "    axes[1].text(v + 0.3, i, label, va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Math: Step by Step\n",
    "\n",
    "Let's look inside the calculation to see exactly how the score emerges from element-wise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detailed_analysis(result, weights):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    axes[0].imshow(result['image'], cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0].set_title(f\"Input: {result['name']}\", fontsize=12, fontweight='bold')\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            color = 'white' if result['image'][i, j] < 0.5 else 'black'\n",
    "            axes[0].text(j, i, f'{result[\"image\"][i, j]:.1f}', ha='center', va='center', fontsize=9, color=color)\n",
    "    \n",
    "    cmap_w = LinearSegmentedColormap.from_list('edge', ['#d62728', 'white', '#1f77b4'])\n",
    "    axes[1].imshow(weights, cmap=cmap_w, vmin=-1, vmax=1)\n",
    "    axes[1].set_title('× Weights', fontsize=12)\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            axes[1].text(j, i, f'{weights[i, j]:+.0f}', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    products = result['products']\n",
    "    max_abs = max(abs(products.min()), abs(products.max()), 0.1)\n",
    "    axes[2].imshow(products, cmap='RdBu', vmin=-max_abs, vmax=max_abs)\n",
    "    axes[2].set_title('= Products (pixel × weight)', fontsize=12)\n",
    "    for i in range(5):\n",
    "        for j in range(5):\n",
    "            axes[2].text(j, i, f'{products[i, j]:+.2f}', ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    axes[3].axis('off')\n",
    "    if result['relu_output'] > 6:\n",
    "        verdict, verdict_color = \"✓ STRONG match!\", '#2ca02c'\n",
    "    elif result['relu_output'] > 2:\n",
    "        verdict, verdict_color = \"~ Partial match\", '#ff7f0e'\n",
    "    elif result['relu_output'] > 0:\n",
    "        verdict, verdict_color = \"~ Weak match\", '#ff7f0e'\n",
    "    else:\n",
    "        verdict, verdict_color = \"✗ Blocked by ReLU\", '#d62728'\n",
    "    \n",
    "    summary = f\"Sum of products:\\nz = {result['weighted_sum']:.2f}\\n\\nAfter ReLU:\\nmax(0, {result['weighted_sum']:.2f}) = {result['relu_output']:.2f}\\n\\n{verdict}\"\n",
    "    axes[3].text(0.1, 0.5, summary, fontsize=13, verticalalignment='center', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', edgecolor=verdict_color, linewidth=2))\n",
    "    \n",
    "    for ax in axes[:3]:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for result in [results[0], results[4], results[3]]:\n",
    "    plot_detailed_analysis(result, edge_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Flattened View: It's Just a Dot Product!\n",
    "\n",
    "The 5×5 matrix representation is convenient for visualization, but the actual computation is simply a **dot product** of two 25-element vectors:\n",
    "\n",
    "$$z = \\vec{x} \\cdot \\vec{w} = x_0 w_0 + x_1 w_1 + \\ldots + x_{24} w_{24}$$\n",
    "\n",
    "Let's see what this looks like when we \"unroll\" the matrices into strips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flattened_view(image, weights, name):\n",
    "    img_flat = image.flatten()\n",
    "    weights_flat = weights.flatten()\n",
    "    products_flat = img_flat * weights_flat\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 5))\n",
    "    cmap_gray = plt.cm.gray\n",
    "    cmap_weights = LinearSegmentedColormap.from_list('edge', ['#d62728', 'white', '#1f77b4'])\n",
    "    \n",
    "    img_colors = cmap_gray(img_flat)\n",
    "    axes[0].bar(range(25), np.ones(25), color=img_colors, edgecolor='black', linewidth=0.5, width=1.0)\n",
    "    axes[0].set_xlim(-0.5, 24.5)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    axes[0].set_ylabel('Image (x)', fontsize=10)\n",
    "    axes[0].set_yticks([])\n",
    "    axes[0].set_xticks([])\n",
    "    for i, v in enumerate(img_flat):\n",
    "        axes[0].text(i, 0.5, f'{v:.1f}', ha='center', va='center', fontsize=7, color='white' if v < 0.5 else 'black')\n",
    "    axes[0].set_title(f'{name}: Flattened into 25-element vectors', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    weight_colors = [cmap_weights((w + 1) / 2) for w in weights_flat]\n",
    "    axes[1].bar(range(25), np.ones(25), color=weight_colors, edgecolor='black', linewidth=0.5, width=1.0)\n",
    "    axes[1].set_xlim(-0.5, 24.5)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_ylabel('Weights (w)', fontsize=10)\n",
    "    axes[1].set_yticks([])\n",
    "    axes[1].set_xticks([])\n",
    "    for i, v in enumerate(weights_flat):\n",
    "        axes[1].text(i, 0.5, f'{v:+.0f}', ha='center', va='center', fontsize=8, fontweight='bold')\n",
    "    \n",
    "    max_abs = max(abs(products_flat.min()), abs(products_flat.max()), 0.1)\n",
    "    product_colors = [plt.cm.RdBu((p / max_abs + 1) / 2) for p in products_flat]\n",
    "    axes[2].bar(range(25), np.ones(25), color=product_colors, edgecolor='black', linewidth=0.5, width=1.0)\n",
    "    axes[2].set_xlim(-0.5, 24.5)\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].set_ylabel('x × w', fontsize=10)\n",
    "    axes[2].set_yticks([])\n",
    "    axes[2].set_xticks([])\n",
    "    for i, v in enumerate(products_flat):\n",
    "        axes[2].text(i, 0.5, f'{v:+.1f}', ha='center', va='center', fontsize=6)\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        for ax in axes[:3]:\n",
    "            ax.axvline(x=i*5-0.5, color='black', linewidth=2)\n",
    "    \n",
    "    axes[3].axis('off')\n",
    "    z = np.sum(products_flat)\n",
    "    axes[3].text(0.5, 0.5, f'z = Σ(x·w) = {z:.2f}    →    ReLU(z) = {max(0, z):.2f}',\n",
    "                ha='center', va='center', fontsize=14, fontweight='bold', family='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightyellow', edgecolor='orange', linewidth=2))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_flattened_view(perfect_edge, edge_weights, \"Perfect Edge\")\n",
    "plot_flattened_view(inverted_edge, edge_weights, \"Inverted Edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insight: Alignment Determines Response\n",
    "\n",
    "The neuron's output depends entirely on **how well the input aligns with the weight pattern**:\n",
    "\n",
    "| Scenario | What Happens | Result |\n",
    "|----------|--------------|--------|\n",
    "| **Perfect match** | Dark pixels × negative weights → positive contributions<br>Bright pixels × positive weights → positive contributions<br>All reinforce! | **High output** |\n",
    "| **Inverted pattern** | Dark pixels × positive weights → small contributions<br>Bright pixels × negative weights → negative contributions | **Negative → blocked** |\n",
    "| **No pattern** | Everything averages out | **~Zero** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Role of Bias: Adjusting Sensitivity\n",
    "\n",
    "So far we've set bias $b = 0$. But what does bias actually do?\n",
    "\n",
    "- **Weights** control *what pattern* the neuron responds to\n",
    "- **Bias** controls *how easily* the neuron activates — it shifts the threshold\n",
    "\n",
    "$$z = \\sum(x \\cdot w) + b$$\n",
    "\n",
    "- **Positive bias** → Easier to activate (even weak matches pass through)\n",
    "- **Negative bias** → Harder to activate (only strong matches pass through)\n",
    "\n",
    "Think of bias as the neuron's \"baseline mood\" — a positive bias means it's eager to fire, while a negative bias means it needs more convincing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "biases = np.arange(-4, 5)\n",
    "z_base_uniform = np.sum(uniform_gray * edge_weights)\n",
    "outputs_uniform = [max(0, z_base_uniform + b) for b in biases]\n",
    "\n",
    "colors = ['#2ca02c' if o > 0 else '#d62728' for o in outputs_uniform]\n",
    "axes[0].bar(biases, outputs_uniform, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[0].axhline(y=0, color='black', linewidth=1)\n",
    "axes[0].axvline(x=0, color='gray', linestyle='--', linewidth=2, label='No bias')\n",
    "axes[0].set_xlabel('Bias Value', fontsize=12)\n",
    "axes[0].set_ylabel('ReLU Output', fontsize=12)\n",
    "axes[0].set_title('Uniform Gray Image\\n(weighted sum = 0 without bias)', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "subtle_edge = np.array([[0.4, 0.4, 0.5, 0.6, 0.6]] * 5)\n",
    "z_base_subtle = np.sum(subtle_edge * edge_weights)\n",
    "outputs_subtle = [max(0, z_base_subtle + b) for b in biases]\n",
    "\n",
    "colors = ['#2ca02c' if o > 0 else '#d62728' for o in outputs_subtle]\n",
    "axes[1].bar(biases, outputs_subtle, color=colors, edgecolor='black', alpha=0.8)\n",
    "axes[1].axhline(y=0, color='black', linewidth=1)\n",
    "axes[1].axvline(x=0, color='gray', linestyle='--', linewidth=2, label='No bias')\n",
    "axes[1].set_xlabel('Bias Value', fontsize=12)\n",
    "axes[1].set_ylabel('ReLU Output', fontsize=12)\n",
    "axes[1].set_title(f'Subtle Edge (low contrast)\\n(weighted sum = {z_base_subtle:.1f} without bias)', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how:\n",
    "- With **negative bias**, even the subtle edge gets blocked\n",
    "- With **positive bias**, weak signals (or even no signal!) can activate the neuron\n",
    "\n",
    "In a trained network, each neuron learns its own optimal bias along with its weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Detectors for Different Patterns\n",
    "\n",
    "Our vertical edge detector is just one example. By changing the weights, we can detect completely different patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = {\n",
    "    'Vertical Edge': np.array([[-1, -1, 0, +1, +1]] * 5, dtype=float),\n",
    "    'Horizontal Edge': np.array([[-1]*5, [-1]*5, [0]*5, [+1]*5, [+1]*5], dtype=float),\n",
    "    'Diagonal Edge': np.array([[-1, -1, -1, 0, +1], [-1, -1, 0, +1, +1], [-1, 0, +1, +1, +1], [0, +1, +1, +1, +1], [+1, +1, +1, +1, +1]], dtype=float),\n",
    "    'Center Spot': np.array([[-1, -1, -1, -1, -1], [-1, +1, +1, +1, -1], [-1, +1, +2, +1, -1], [-1, +1, +1, +1, -1], [-1, -1, -1, -1, -1]], dtype=float) / 2,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
    "cmap_w = LinearSegmentedColormap.from_list('edge', ['#d62728', 'white', '#1f77b4'])\n",
    "\n",
    "for idx, (name, weights) in enumerate(detectors.items()):\n",
    "    axes[0, idx].imshow(weights, cmap=cmap_w, vmin=-1, vmax=1)\n",
    "    axes[0, idx].set_title(name, fontsize=11, fontweight='bold')\n",
    "    axes[0, idx].set_xticks([])\n",
    "    axes[0, idx].set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel('Detector\\nWeights', fontsize=12, fontweight='bold')\n",
    "\n",
    "for idx, (name, weights) in enumerate(detectors.items()):\n",
    "    z = np.sum(perfect_edge * weights)\n",
    "    output = max(0, z)\n",
    "    color = '#2ca02c' if output > 3 else '#ff7f0e' if output > 0 else '#d62728'\n",
    "    axes[1, idx].bar(['Response'], [output], color=color, edgecolor='black', linewidth=2)\n",
    "    axes[1, idx].set_ylim(0, 10)\n",
    "    axes[1, idx].set_title(f'z={z:.1f} → {output:.1f}', fontsize=11)\n",
    "\n",
    "axes[1, 0].set_ylabel('Response to\\nVertical Edge', fontsize=12, fontweight='bold')\n",
    "plt.suptitle('Different Detectors Respond to Different Patterns', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Single Neurons to Deep Networks\n",
    "\n",
    "A real neural network has thousands or millions of neurons arranged in layers:\n",
    "\n",
    "- **Layer 1** neurons learn simple patterns (edges, colors, textures)\n",
    "- **Layer 2** neurons combine Layer 1 outputs to detect shapes (curves, corners)\n",
    "- **Layer 3** neurons combine shapes into parts (eyes, wheels, windows)\n",
    "- **Output layer** combines parts into final classifications (cat, car, digit)\n",
    "\n",
    "This hierarchy — from simple to complex — is why deep learning works so well. And it all starts with the simple pattern matching we've explored here!\n",
    "\n",
    "**The key insight:** We don't design these weights by hand. During training, the network automatically discovers what patterns are useful for the task. Backpropagation adjusts each weight to reduce errors, and useful detectors emerge naturally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It Yourself!\n",
    "\n",
    "Modify the image below and re-run to see how the detector responds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = np.array([\n",
    "    [0.0, 0.0, 0.5, 1.0, 1.0],\n",
    "    [0.0, 0.0, 0.5, 1.0, 1.0],\n",
    "    [0.0, 0.0, 0.5, 1.0, 1.0],\n",
    "    [0.0, 0.0, 0.5, 1.0, 1.0],\n",
    "    [0.0, 0.0, 0.5, 1.0, 1.0]\n",
    "])\n",
    "\n",
    "my_result = analyze_response(my_image, edge_weights, \"My Custom Image\")\n",
    "plot_detailed_analysis(my_result, edge_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "We've built an edge detector from scratch and discovered the core principles that power all neural networks:\n",
    "\n",
    "| Concept | What It Does | Analogy |\n",
    "|---------|--------------|----------|\n",
    "| **Weights** | Define what pattern the neuron detects | A template to match against |\n",
    "| **Weighted Sum** | Measure how well input matches the pattern | A similarity score |\n",
    "| **Bias** | Shift the activation threshold | The neuron's \"eagerness\" to fire |\n",
    "| **ReLU** | Block negative responses | A gate that only passes matches |\n",
    "\n",
    "### The Big Ideas\n",
    "\n",
    "1. **A neuron is a pattern matcher.** High output = good match, zero output = poor match.\n",
    "\n",
    "2. **Weights encode knowledge.** The specific values determine what the neuron \"looks for.\"\n",
    "\n",
    "3. **Learning = finding good weights.** Training adjusts weights until useful patterns emerge.\n",
    "\n",
    "4. **Depth creates hierarchy.** Simple detectors combine into complex recognizers.\n",
    "\n",
    "This simple mechanism — multiply, sum, activate — repeated billions of times with learned weights, is how neural networks learn to see, read, translate, and even generate art.\n",
    "\n",
    "---\n",
    "\n",
    "*Now you understand the atom of deep learning. Everything else is scale and clever architecture!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
